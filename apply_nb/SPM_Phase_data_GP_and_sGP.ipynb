{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d50845",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/utkarshp1161/Active-learning-in-microscopy/blob/apply/apply_nb/GP_and_sGP_beyond_1D.ipynb)\n",
    "\n",
    "# GP & sGP for Phase Data in Scanning Probe Microscopy (SPM)\n",
    "\n",
    "This notebook demonstrates the implementation of Gaussian Process (GP) and Sparse Gaussian Process (sGP) for Phase data in Scanning Probe Microscopy (SPM).\n",
    "\n",
    "- **Prepared by:** [Utkarsh Pratiush](https://github.com/utkarshp1161)  \n",
    "- **Data & Ideas Discussion with:** [Richard Liu](https://github.com/RichardLiuCoding) and [SVK](https://github.com/SergeiVKalinin)\n",
    "\n",
    "### Reference:\n",
    "This implementation is based on the original notebook:[sGP Notebook](https://github.com/utkarshp1161/Active-learning-in-microscopy/blob/main/notebooks/GP_%26_sGP_beyond_1D.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e14c0b1",
   "metadata": {},
   "source": [
    "## 1a. Install and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fcfc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install\n",
    "!pip install -q botorch==0.12.0\n",
    "!pip install -q gpytorch==1.13\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import gpytorch\n",
    "import botorch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf_discrete\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e4f81",
   "metadata": {},
   "source": [
    "## 1b. Download Data and set: Ground truth function : \n",
    "    - Choose either phases.txt or phases_masked.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc5d081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --id 1soIQoCWjyZVhvVO3FSdWMxQbLvGM_3P4 #phases.txt\n",
    "# !gdown --id 1jyef_BgqpqI2QEnrnjSCcPmYDM3Z9wUO #phases_masked.txt\n",
    "import os\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Ensure the data directory exists\n",
    "data_dir = \"../data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Download the files if in Colab\n",
    "if IN_COLAB:\n",
    "    if not os.path.exists(os.path.join(data_dir, \"phases.txt\")):\n",
    "        !gdown --id 1soIQoCWjyZVhvVO3FSdWMxQbLvGM_3P4 -O {data_dir}/phases.txt\n",
    "    if not os.path.exists(os.path.join(data_dir, \"phases_masked.txt\")):\n",
    "        !gdown --id 1jyef_BgqpqI2QEnrnjSCcPmYDM3Z9wUO -O {data_dir}/phases_masked.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee808d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the data globally so it's accessible to the function\n",
    "t = np.linspace(0, 1, 100)\n",
    "x_grid, y_grid = np.meshgrid(t, t)\n",
    "# Load the data\n",
    "z_data = np.loadtxt(os.path.join(data_dir, \"phases.txt\")).reshape(100, 100)\n",
    "\n",
    "def test_function(X, ndim=2):\n",
    "    \"\"\"\n",
    "    Function that returns values from the loaded data array\n",
    "    Args:\n",
    "        X: Input tensor of shape (n_points, ndim)\n",
    "        ndim: Number of dimensions (only 2D is supported in this version)\n",
    "    Returns:\n",
    "        Y: Output tensor of shape (n_points, 1)\n",
    "    \"\"\"\n",
    "    if ndim != 2:\n",
    "        raise ValueError(\"This function only supports 2D inputs\")\n",
    "    \n",
    "    # Convert input tensor to numpy array\n",
    "    X_np = X.numpy()\n",
    "    \n",
    "    # Scale inputs from [-5, 5] to [0, 1] range (assuming your visualization uses [-5, 5])\n",
    "    X_scaled = X_np#(X_np + 5) / 10\n",
    "    \n",
    "    # Find nearest indices in the grid\n",
    "    x_idx = np.clip((X_scaled[:, 0] * 99).astype(int), 0, 99)\n",
    "    y_idx = np.clip((X_scaled[:, 1] * 99).astype(int), 0, 99)\n",
    "    \n",
    "    # Get values from z_data array\n",
    "    values = z_data[y_idx, x_idx]\n",
    "    \n",
    "    # Convert back to torch tensor\n",
    "    return torch.tensor(values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# The visualization function can remain the same\n",
    "def visualize_ground_truth_function(func, ndim=2, resolution=50):\n",
    "    \"\"\"\n",
    "    Visualize function in 2D and 3D side by side\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # 2D Visualization\n",
    "    plt.subplot(121)\n",
    "    x = np.linspace(0, 1, resolution)\n",
    "    y = np.linspace(0, 1, resolution)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    points = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    Z = func(torch.tensor(points).float())\n",
    "    Z = Z.reshape(resolution, resolution).numpy()\n",
    "    \n",
    "    plt.contour(X, Y, Z, levels=20)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"2D Visualization\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    \n",
    "    # 3D Visualization\n",
    "    ax = plt.subplot(122, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    plt.colorbar(surf)\n",
    "    ax.set_title(\"3D Visualization\")\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_zlabel(\"f(x)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize\n",
    "visualize_ground_truth_function(test_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare the data\n",
    "t = np.linspace(0, 1, 100)\n",
    "x, y = np.meshgrid(t, t)\n",
    "z = np.loadtxt(\"../data/phases_masked.txt\")  # This should be of shape (10000,)\n",
    "z_2d = z.reshape(100, 100)  # Reshape to 2D grid\n",
    "\n",
    "# Define new test function\n",
    "def test_function(X, ndim=2):\n",
    "    \"\"\"\n",
    "    Function that returns values from the loaded data\n",
    "    Args:\n",
    "        X: Input tensor of shape (n_points, ndim)\n",
    "        ndim: Number of input dimensions (only 2D supported in this version)\n",
    "    Returns:\n",
    "        Y: Output tensor of shape (n_points, 1)\n",
    "    \"\"\"\n",
    "    if ndim != 2:\n",
    "        raise ValueError(\"This function only supports 2D inputs\")\n",
    "    \n",
    "    # Convert input to numpy for easier indexing\n",
    "    X_np = X.numpy()\n",
    "    \n",
    "    # Scale inputs from [-5, 5] to [0, 1] range\n",
    "    X_scaled = X_np#(X_np + 5) / 10\n",
    "    \n",
    "    # Get nearest indices\n",
    "    x_idx = np.clip((X_scaled[:, 0] * 99).astype(int), 0, 99)\n",
    "    y_idx = np.clip((X_scaled[:, 1] * 99).astype(int), 0, 99)\n",
    "    \n",
    "    # Get corresponding z values\n",
    "    z_values = z_2d[y_idx, x_idx]\n",
    "    \n",
    "    return torch.tensor(z_values).float().unsqueeze(-1)\n",
    "\n",
    "# The visualization function remains the same\n",
    "def visualize_ground_truth_function(func, ndim=2, resolution=50):\n",
    "    \"\"\"\n",
    "    Visualize function in 2D and 3D side by side\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # 2D Visualization\n",
    "    plt.subplot(121)\n",
    "    x = np.linspace(0, 1, resolution)\n",
    "    y = np.linspace(0, 1, resolution)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    points = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    Z = func(torch.tensor(points).float())\n",
    "    Z = Z.reshape(resolution, resolution).numpy()\n",
    "    \n",
    "    plt.contour(X, Y, Z, levels=20)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"2D Visualization\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    \n",
    "    # 3D Visualization\n",
    "    ax = plt.subplot(122, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    plt.colorbar(surf)\n",
    "    ax.set_title(\"3D Visualization\")\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_zlabel(\"f(x)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize\n",
    "visualize_ground_truth_function(test_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de51a2",
   "metadata": {},
   "source": [
    "## 1c. Define kernel\n",
    "- For more information on defining kernel - see [this notebook](https://github.com/utkarshp1161/Active-learning-in-microscopy/blob/main/notebooks/GP_%26_sGP_BO_BoTorch.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## kernel\n",
    "# Define the custom kernel\n",
    "class CustomKernel(gpytorch.kernels.Kernel):\n",
    "    def __init__(self, input_dim, lengthscale_prior=None, outputscale_prior=None):\n",
    "        super().__init__()\n",
    "        self.base_kernel = gpytorch.kernels.RBFKernel(\n",
    "            ard_num_dims=input_dim,\n",
    "            lengthscale_prior=lengthscale_prior\n",
    "        )\n",
    "        self.scaling_kernel = gpytorch.kernels.ScaleKernel(\n",
    "            self.base_kernel,\n",
    "            outputscale_prior=outputscale_prior\n",
    "        )\n",
    "        \n",
    "    def forward(self, x1, x2, **params):\n",
    "        return self.scaling_kernel.forward(x1, x2, **params)\n",
    "\n",
    "# Create sample data\n",
    "x = torch.linspace(-3, 3, 100).view(-1, 1)\n",
    "kernel = CustomKernel(input_dim=1)\n",
    "\n",
    "# Compute kernel matrix\n",
    "K = kernel(x, x).evaluate().detach().numpy()\n",
    "\n",
    "# Plot the kernel matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(K, cmap='viridis')\n",
    "plt.colorbar(label='Kernel value')\n",
    "plt.title('Custom Kernel Matrix')\n",
    "plt.xlabel('Index i')\n",
    "plt.ylabel('Index j')\n",
    "plt.show()\n",
    "\n",
    "# Plot a slice of the kernel\n",
    "x0 = torch.zeros(1, 1)\n",
    "k_slice = kernel(x, x0).evaluate().detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x.numpy(), k_slice)\n",
    "plt.title('Kernel Slice (k(x, 0))')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('k(x, 0)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ebcd3",
   "metadata": {},
   "source": [
    "## 1d. GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f94a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.means import ConstantMean\n",
    "\n",
    "class SimpleGP(SingleTaskGP):\n",
    "    def __init__(self, train_X, train_Y, covar_module, likelihood):\n",
    "        super().__init__(train_X, train_Y)\n",
    "        self.mean_module = ConstantMean()  # Constant mean function\n",
    "        self.covar_module = covar_module\n",
    "        self.likelihood = likelihood\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Sample points function remains the same\n",
    "def sample_points(ndim, n_points, bounds=(0, 1)):\n",
    "    return torch.rand(n_points, ndim) * (bounds[1] - bounds[0]) + bounds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46a5a33",
   "metadata": {},
   "source": [
    "## 1e. Plotting utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ae3663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_step(model, train_X, train_Y, next_point=None, ndim=2):\n",
    "    \"\"\"Plot current state of optimization\"\"\"\n",
    "    if ndim > 2:\n",
    "        print(\"Visualization only supported for 1D and 2D inputs\")\n",
    "        return\n",
    "    \n",
    "    if ndim == 2:\n",
    "        # Create meshgrid\n",
    "        x1 = torch.linspace(0, 1, 100)\n",
    "        x2 = torch.linspace(0, 1, 100)\n",
    "        x1_grid, x2_grid = torch.meshgrid(x1, x2)\n",
    "        grid_points = torch.stack([x1_grid.flatten(), x2_grid.flatten()], dim=-1)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            posterior = model.posterior(grid_points)\n",
    "            mean = posterior.mean.squeeze()  # Add squeeze to handle single-output case\n",
    "            lower, upper = posterior.confidence_region()\n",
    "        \n",
    "        # Reshape for plotting\n",
    "        mean_surface = mean.reshape(100, 100)\n",
    "        std_surface = ((upper - lower) / 2).reshape(100, 100)\n",
    "        true_values = test_function(grid_points, ndim).reshape(100, 100)\n",
    "        \n",
    "        # Create plots\n",
    "        fig = plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # True function\n",
    "        ax1 = fig.add_subplot(131)\n",
    "        c1 = ax1.contourf(x1_grid, x2_grid, true_values, levels=20)\n",
    "        plt.colorbar(c1, ax=ax1)\n",
    "        ax1.set_title('True Function')\n",
    "        ax1.scatter(train_X[:, 0], train_X[:, 1], c='red', marker='x', label='Training points')\n",
    "        if next_point is not None and next_point.numel() > 0:  # Check if next_point exists and is not empty\n",
    "            ax1.scatter(next_point[0, 0], next_point[0, 1], c='green', marker='o', label='Next point')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Posterior mean\n",
    "        ax2 = fig.add_subplot(132)\n",
    "        c2 = ax2.contourf(x1_grid, x2_grid, mean_surface, levels=20)\n",
    "        plt.colorbar(c2, ax=ax2)\n",
    "        ax2.set_title('Posterior Mean')\n",
    "        ax2.scatter(train_X[:, 0], train_X[:, 1], c='red', marker='x')\n",
    "        if next_point is not None and next_point.numel() > 0:\n",
    "            ax2.scatter(next_point[0, 0], next_point[0, 1], c='green', marker='o')\n",
    "        \n",
    "        # Posterior std\n",
    "        ax3 = fig.add_subplot(133)\n",
    "        c3 = ax3.contourf(x1_grid, x2_grid, std_surface, levels=20)\n",
    "        plt.colorbar(c3, ax=ax3)\n",
    "        ax3.set_title('Posterior Std Dev')\n",
    "        ax3.scatter(train_X[:, 0], train_X[:, 1], c='red', marker='x')\n",
    "        if next_point is not None and next_point.numel() > 0:\n",
    "            ax3.scatter(next_point[0, 0], next_point[0, 1], c='green', marker='o')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif ndim == 1:\n",
    "        x_plot = torch.linspace(train_X.min(), train_X.max(), 100).reshape(-1, 1)\n",
    "        \n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            posterior = model.posterior(x_plot)\n",
    "            mean = posterior.mean.squeeze()\n",
    "            lower, upper = posterior.confidence_region()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(x_plot.numpy(), mean.numpy(), 'b-', label='Posterior Mean')\n",
    "        plt.fill_between(x_plot.numpy().flatten(), \n",
    "                        lower.numpy(), \n",
    "                        upper.numpy(), \n",
    "                        alpha=0.2, \n",
    "                        label='95% Confidence')\n",
    "        plt.scatter(train_X.numpy(), train_Y.numpy(), c='red', \n",
    "                    marker='x', label='Training Points')\n",
    "        if next_point is not None and next_point.numel() > 0:\n",
    "            next_y = test_function(next_point, ndim)\n",
    "            plt.scatter(next_point.numpy(), next_y.numpy(), \n",
    "                       c='green', marker='o', label='Next point')\n",
    "        plt.legend()\n",
    "        plt.title('GP Posterior')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bd046",
   "metadata": {},
   "source": [
    "## 1f. Training GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc235126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    ndim = 2\n",
    "    n_initial = 50\n",
    "    n_test = 10000\n",
    "    \n",
    "    # Generate initial data\n",
    "    train_X = sample_points(ndim, n_initial, bounds=(0, 1))\n",
    "    train_Y = test_function(train_X, ndim)\n",
    "    \n",
    "    # # Define priors\n",
    "    # lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "    # outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "    # noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "\n",
    "    # Conservative/Standard priors\n",
    "    lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 1.0)  # mean = 3.0, variance = 3.0\n",
    "    outputscale_prior = gpytorch.priors.GammaPrior(2.0, 2.0)  # mean = 1.0, variance = 0.5\n",
    "    noise_prior = gpytorch.priors.GammaPrior(1.5, 3.0)        # mean = 0.5, variance = 0.17\n",
    "\n",
    "    # Define model components\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "    covar_module = CustomKernel(\n",
    "        ndim,\n",
    "        lengthscale_prior=lengthscale_prior,\n",
    "        outputscale_prior=outputscale_prior\n",
    "    )\n",
    "    \n",
    "    # Initialize and fit model\n",
    "    model = SimpleGP(train_X, train_Y, covar_module, likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    \n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), next_point=None, ndim=ndim)  # Squeeze for plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff01dfb",
   "metadata": {},
   "source": [
    "# 2. Active learning with GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 1\n",
    "n_iterations = 15\n",
    "beta = 1e6### --> higher means more exploration\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim).unsqueeze(-1)  # Add extra dimension here --> so concatenation works fine in the loop\n",
    "\n",
    "# Generate candidate points for discrete optimization\n",
    "n_candidates = 1000\n",
    "candidates = sample_points(ndim, n_candidates)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Define priors\n",
    "    # lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "    # outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "    # noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "    # Conservative/Standard priors\n",
    "    lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 1.0)  # mean = 3.0, variance = 3.0\n",
    "    outputscale_prior = gpytorch.priors.GammaPrior(2.0, 2.0)  # mean = 1.0, variance = 0.5\n",
    "    noise_prior = gpytorch.priors.GammaPrior(1.5, 3.0)        # mean = 0.5, variance = 0.17\n",
    "\n",
    "    # Define model components\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "    covar_module = CustomKernel(\n",
    "        ndim,\n",
    "        lengthscale_prior=lengthscale_prior,\n",
    "        outputscale_prior=outputscale_prior\n",
    "    )\n",
    "\n",
    "    # Initialize and fit model\n",
    "    model = SimpleGP(train_X, train_Y.squeeze(-1), covar_module, likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Define acquisition function (UCB with beta=1e6)\n",
    "    UCB = UpperConfidenceBound(model, beta=beta)\n",
    "\n",
    "    # Optimize acquisition function\n",
    "    next_point, acq_value = optimize_acqf_discrete(\n",
    "        acq_function=UCB,\n",
    "        choices=candidates,\n",
    "        q=1,\n",
    "    )\n",
    "\n",
    "    # Plot with next point\n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), next_point, ndim=ndim)  # Squeeze for plotting\n",
    "\n",
    "    # Evaluate next point and update training data\n",
    "    next_value = test_function(next_point, ndim).unsqueeze(-1)  # Add extra dimension\n",
    "    train_X = torch.cat([train_X, next_point])\n",
    "    train_Y = torch.cat([train_Y, next_value])  # Now dimensions match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ada7ce",
   "metadata": {},
   "source": [
    "# 3 sGP - with mean function prior\n",
    "- Good idea to visit [this sGP notebook first](https://github.com/utkarshp1161/Active-learning-in-microscopy/blob/main/notebooks/GP_%26_sGP_BO_BoTorch.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb311572",
   "metadata": {},
   "source": [
    "## 3a. Define cusom mean and sGP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb092093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP Model\n",
    "class CustomGP(SingleTaskGP):\n",
    "    def __init__(self, train_X, train_Y, mean_module, covar_module, likelihood):\n",
    "        super().__init__(train_X, train_Y)\n",
    "        self.mean_module = mean_module\n",
    "        self.covar_module = covar_module\n",
    "        self.likelihood = likelihood\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a3007",
   "metadata": {},
   "source": [
    "### 3a. i) Custom mean function 1 - Determisnistic function based on the simulator by Richard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class PhaseDataMean(gpytorch.means.Mean):\n",
    "    def __init__(self, input_size=2):\n",
    "        super().__init__()\n",
    "        self.register_parameter(\n",
    "            name='amplitude',\n",
    "            parameter=torch.nn.Parameter(torch.ones(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='frequency',\n",
    "            parameter=torch.nn.Parameter(torch.ones(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='offset',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='scale',\n",
    "            parameter=torch.nn.Parameter(torch.tensor([0.75]))\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Combines the specific function x = sqrt(y)/0.75 - 0.5 with periodic components\n",
    "        Args:\n",
    "            x: Input tensor of shape (n_points, 2)\n",
    "        Returns:\n",
    "            mean: Output tensor of shape (n_points)\n",
    "        \"\"\"\n",
    "        # Extract x and y components\n",
    "        x1, x2 = x[..., 0], x[..., 1]\n",
    "        \n",
    "        # Implement the specific function\n",
    "        function_term = torch.sqrt(torch.abs(x2))/self.scale - 0.5\n",
    "        \n",
    "        # Periodic component\n",
    "        r = torch.sqrt(x1**2 + x2**2)\n",
    "        periodic_term = self.amplitude * torch.cos(self.frequency * r)\n",
    "        \n",
    "        # Combine terms\n",
    "        return function_term + periodic_term + self.offset\n",
    "\n",
    "def visualize_mean_function(mean_function, resolution=50):\n",
    "    \"\"\"\n",
    "    Visualize the custom mean function in 2D and 3D\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Create grid of points\n",
    "    x = np.linspace(-2, 2, resolution)\n",
    "    y = np.linspace(0, 4, resolution)  # Using only positive values for y due to sqrt\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    points = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        Z = mean_function(torch.tensor(points, dtype=torch.float32))\n",
    "        Z = Z.reshape(resolution, resolution).numpy()\n",
    "    \n",
    "    # 2D Visualization\n",
    "    plt.subplot(121)\n",
    "    plt.contour(X, Y, Z, levels=20)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Mean Function (2D)\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    \n",
    "    # 3D Visualization\n",
    "    ax = plt.subplot(122, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    plt.colorbar(surf)\n",
    "    ax.set_title(\"Mean Function (3D)\")\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_zlabel(\"f(x)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Initialize and visualize\n",
    "mean_function = PhaseDataMean(input_size=2)\n",
    "visualize_mean_function(mean_function)\n",
    "\n",
    "# Additional visualization of the specific function\n",
    "plt.figure(figsize=(8, 6))\n",
    "y = np.linspace(0, 4, 100)\n",
    "x = np.sqrt(y)/0.75 - 0.5\n",
    "plt.plot(x, y, 'b-', label='x = sqrt(y)/0.75 - 0.5')\n",
    "plt.grid(True)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Original Function')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149aca1b",
   "metadata": {},
   "source": [
    "#### 3a. i.a) Train sGP model for custom mean function 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a7625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 50\n",
    "n_test = 10000\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim)\n",
    "\n",
    "# # Define priors\n",
    "# lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "# outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "\n",
    "# Conservative/Standard priors\n",
    "# lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 1.0)  # mean = 3.0, variance = 3.0\n",
    "# outputscale_prior = gpytorch.priors.GammaPrior(2.0, 2.0)  # mean = 1.0, variance = 0.5\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1.5, 3.0)        # mean = 0.5, variance = 0.17\n",
    "# Priors for Sparse GP with RBF/Matern kernel\n",
    "lengthscale_prior = gpytorch.priors.GammaPrior(2.0, 4.0)  # mean=0.5, more local variations\n",
    "outputscale_prior = gpytorch.priors.GammaPrior(4.0, 4.0)  # mean=1.0, moderate variance\n",
    "noise_prior = gpytorch.priors.GammaPrior(1.5, 6.0)        # mean=0.25, small noise\n",
    "\n",
    "\n",
    "\n",
    "# Define model components\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "# mean_module = CustomMean(ndim)\n",
    "mean_module = mean_function\n",
    "covar_module = CustomKernel(\n",
    "    ndim,\n",
    "    lengthscale_prior=lengthscale_prior,\n",
    "    outputscale_prior=outputscale_prior\n",
    ")\n",
    "\n",
    "# Initialize and fit model\n",
    "model = CustomGP(train_X, train_Y, mean_module, covar_module, likelihood)\n",
    "mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "plot_step(model, train_X, train_Y.squeeze(-1), ndim=ndim)  # Squeeze for plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a76f895",
   "metadata": {},
   "source": [
    "#### 3a. i.b) Active learing for custom mean function 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 1\n",
    "n_iterations = 15\n",
    "beta = 1e6### --> higher means more exploration\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim).unsqueeze(-1)  # Add extra dimension here --> so concatenation works fine in the loop\n",
    "\n",
    "# Generate candidate points for discrete optimization\n",
    "n_candidates = 1000\n",
    "candidates = sample_points(ndim, n_candidates)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Define priors\n",
    "    # lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "    # outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "    # noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "    # Conservative/Standard priors\n",
    "    lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 1.0)  # mean = 3.0, variance = 3.0\n",
    "    outputscale_prior = gpytorch.priors.GammaPrior(2.0, 2.0)  # mean = 1.0, variance = 0.5\n",
    "    noise_prior = gpytorch.priors.GammaPrior(1.5, 3.0)        # mean = 0.5, variance = 0.17\n",
    "\n",
    "    # Define model components\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "    # mean_module = CustomMean(ndim)\n",
    "    covar_module = CustomKernel(\n",
    "        ndim,\n",
    "        lengthscale_prior=lengthscale_prior,\n",
    "        outputscale_prior=outputscale_prior\n",
    "    )\n",
    "\n",
    "    # Initialize and fit model\n",
    "    model = CustomGP(train_X, train_Y.squeeze(-1), mean_module, covar_module, likelihood)  # Squeeze here for CustomGP\n",
    "    mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Plot current state\n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), ndim=ndim)  # Squeeze for plotting\n",
    "\n",
    "    # Define acquisition function (UCB with beta=1e6)\n",
    "    UCB = UpperConfidenceBound(model, beta=beta)\n",
    "\n",
    "    # Optimize acquisition function\n",
    "    next_point, acq_value = optimize_acqf_discrete(\n",
    "        acq_function=UCB,\n",
    "        choices=candidates,\n",
    "        q=1,\n",
    "    )\n",
    "\n",
    "    # Plot with next point\n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), next_point, ndim=ndim)  # Squeeze for plotting\n",
    "\n",
    "    # Evaluate next point and update training data\n",
    "    next_value = test_function(next_point, ndim).unsqueeze(-1)  # Add extra dimension\n",
    "    train_X = torch.cat([train_X, next_point])\n",
    "    train_Y = torch.cat([train_Y, next_value])  # Now dimensions match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b7636",
   "metadata": {},
   "source": [
    "### 3a. ii) Custom mean function 2 - based on the idea of a Quadratic boundary - has priors on the terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34166d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gpytorch.priors import LogNormalPrior, NormalPrior\n",
    "from gpytorch.constraints import Positive, Interval\n",
    "\n",
    "class QuadraticBoundaryMean(gpytorch.means.Mean):\n",
    "    def __init__(self, batch_shape=torch.Size()):\n",
    "        super().__init__()\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name=\"raw_center_x\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_center_y\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_scale\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))  # log(1) = 0\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_a\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_b\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_theta\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "\n",
    "        # Register constraints\n",
    "        self.register_constraint(\"raw_center_x\", Interval(-5.0, 5.0))\n",
    "        self.register_constraint(\"raw_center_y\", Interval(-5.0, 5.0))\n",
    "        self.register_constraint(\"raw_scale\", Positive())\n",
    "        self.register_constraint(\"raw_a\", Positive())\n",
    "        self.register_constraint(\"raw_b\", Positive())\n",
    "        self.register_constraint(\"raw_theta\", Interval(-np.pi, np.pi))\n",
    "\n",
    "        # Register priors\n",
    "        self.register_prior(\n",
    "            \"center_x_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.center_x,\n",
    "            lambda module, value: module._set_center_x(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"center_y_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.center_y,\n",
    "            lambda module, value: module._set_center_y(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"scale_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.scale,\n",
    "            lambda module, value: module._set_scale(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"a_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.a,\n",
    "            lambda module, value: module._set_a(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"b_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.b,\n",
    "            lambda module, value: module._set_b(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"theta_prior\",\n",
    "            NormalPrior(0.0, np.pi/4),\n",
    "            lambda module: module.theta,\n",
    "            lambda module, value: module._set_theta(value)\n",
    "        )\n",
    "\n",
    "    # Properties\n",
    "    @property\n",
    "    def center_x(self):\n",
    "        return self.raw_center_x_constraint.transform(self.raw_center_x)\n",
    "\n",
    "    @property\n",
    "    def center_y(self):\n",
    "        return self.raw_center_y_constraint.transform(self.raw_center_y)\n",
    "\n",
    "    @property\n",
    "    def scale(self):\n",
    "        return self.raw_scale_constraint.transform(self.raw_scale)\n",
    "\n",
    "    @property\n",
    "    def a(self):\n",
    "        return self.raw_a_constraint.transform(self.raw_a)\n",
    "\n",
    "    @property\n",
    "    def b(self):\n",
    "        return self.raw_b_constraint.transform(self.raw_b)\n",
    "\n",
    "    @property\n",
    "    def theta(self):\n",
    "        return self.raw_theta_constraint.transform(self.raw_theta)\n",
    "\n",
    "    # Setters\n",
    "    def _set_center_x(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_center_x=self.raw_center_x_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_center_y(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_center_y=self.raw_center_y_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_scale(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_scale=self.raw_scale_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_a(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_a=self.raw_a_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_b(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_b=self.raw_b_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_theta(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_theta=self.raw_theta_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndimension() == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "\n",
    "        x1, x2 = x[..., 0], x[..., 1]\n",
    "        \n",
    "        # Translate points to center\n",
    "        x1_t = x1 - self.center_x\n",
    "        x2_t = x2 - self.center_y\n",
    "        \n",
    "        # Rotate points\n",
    "        cos_theta = torch.cos(self.theta)\n",
    "        sin_theta = torch.sin(self.theta)\n",
    "        x1_r = x1_t * cos_theta + x2_t * sin_theta\n",
    "        x2_r = -x1_t * sin_theta + x2_t * cos_theta\n",
    "        \n",
    "        # Compute normalized distance\n",
    "        dist = (x1_r/self.a)**2 + (x2_r/self.b)**2\n",
    "        boundary = self.scale\n",
    "        \n",
    "        # Smooth transition between inside and outside\n",
    "        smoothing_factor = 10.0\n",
    "        return torch.sigmoid(smoothing_factor * (dist - boundary))\n",
    "\n",
    "def plot_mean_function(mean_module, resolution=100):\n",
    "    \"\"\"\n",
    "    Visualize the mean function in 2D and 3D\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Create grid of points\n",
    "    x = np.linspace(-3, 3, resolution)\n",
    "    y = np.linspace(-3, 3, resolution)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    points = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        Z = mean_module(torch.tensor(points, dtype=torch.float32))\n",
    "        Z = Z.reshape(resolution, resolution).numpy()\n",
    "    \n",
    "    # 2D Visualization\n",
    "    plt.subplot(121)\n",
    "    plt.contour(X, Y, Z, levels=20)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Mean Function (2D)\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    \n",
    "    # 3D Visualization\n",
    "    ax = plt.subplot(122, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    plt.colorbar(surf)\n",
    "    ax.set_title(\"Mean Function (3D)\")\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_zlabel(\"f(x)\")\n",
    "    \n",
    "    # Show parameter values\n",
    "    param_text = (f'Parameters:\\nCenter: ({mean_module.center_x.item():.3f}, '\n",
    "                 f'{mean_module.center_y.item():.3f})\\n'\n",
    "                 f'Scale: {mean_module.scale.item():.3f}\\n'\n",
    "                 f'a: {mean_module.a.item():.3f}\\n'\n",
    "                 f'b: {mean_module.b.item():.3f}\\n'\n",
    "                 f'Î¸: {mean_module.theta.item():.3f}')\n",
    "\n",
    "    # plt.text(0.02, 0.98, param_text,\n",
    "    #          transform=plt.gca().transAxes,\n",
    "    #          verticalalignment='top',\n",
    "    #          bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Initialize and visualize\n",
    "mean_module = QuadraticBoundaryMean()\n",
    "plot_mean_function(mean_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fccf7fd",
   "metadata": {},
   "source": [
    "#### 3a. ii.a) Train sGP model for custom mean function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 50\n",
    "n_test = 10000\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim)\n",
    "\n",
    "# # Define priors\n",
    "# lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "# outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "\n",
    "# Conservative/Standard priors\n",
    "# lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 1.0)  # mean = 3.0, variance = 3.0\n",
    "# outputscale_prior = gpytorch.priors.GammaPrior(2.0, 2.0)  # mean = 1.0, variance = 0.5\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1.5, 3.0)        # mean = 0.5, variance = 0.17\n",
    "# Priors for Sparse GP with RBF/Matern kernel\n",
    "lengthscale_prior = gpytorch.priors.GammaPrior(2.0, 4.0)  # mean=0.5, more local variations\n",
    "outputscale_prior = gpytorch.priors.GammaPrior(4.0, 4.0)  # mean=1.0, moderate variance\n",
    "noise_prior = gpytorch.priors.GammaPrior(1.5, 6.0)        # mean=0.25, small noise\n",
    "\n",
    "\n",
    "\n",
    "# Define model components\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "# mean_module = CustomMean(ndim)\n",
    "mean_module = mean_function\n",
    "covar_module = CustomKernel(\n",
    "    ndim,\n",
    "    lengthscale_prior=lengthscale_prior,\n",
    "    outputscale_prior=outputscale_prior\n",
    ")\n",
    "\n",
    "# Initialize and fit model\n",
    "model = CustomGP(train_X, train_Y, mean_module, covar_module, likelihood)\n",
    "mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "plot_step(model, train_X, train_Y.squeeze(-1), ndim=ndim)  # Squeeze for plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020678f",
   "metadata": {},
   "source": [
    "#### 3a. ii.b) Active learing for custom mean function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49774d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 1\n",
    "n_iterations = 15\n",
    "beta = 1e6### --> higher means more exploration\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim).unsqueeze(-1)  # Add extra dimension here --> so concatenation works fine in the loop\n",
    "\n",
    "# Generate candidate points for discrete optimization\n",
    "n_candidates = 1000\n",
    "candidates = sample_points(ndim, n_candidates)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Define priors\n",
    "    # lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "    # outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "    # noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "    # Conservative/Standard priors\n",
    "    lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 1.0)  # mean = 3.0, variance = 3.0\n",
    "    outputscale_prior = gpytorch.priors.GammaPrior(2.0, 2.0)  # mean = 1.0, variance = 0.5\n",
    "    noise_prior = gpytorch.priors.GammaPrior(1.5, 3.0)        # mean = 0.5, variance = 0.17\n",
    "\n",
    "    # Define model components\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "    # mean_module = CustomMean(ndim)\n",
    "    covar_module = CustomKernel(\n",
    "        ndim,\n",
    "        lengthscale_prior=lengthscale_prior,\n",
    "        outputscale_prior=outputscale_prior\n",
    "    )\n",
    "\n",
    "    # Initialize and fit model\n",
    "    model = CustomGP(train_X, train_Y.squeeze(-1), mean_module, covar_module, likelihood)  # Squeeze here for CustomGP\n",
    "    mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Plot current state\n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), ndim=ndim)  # Squeeze for plotting\n",
    "\n",
    "    # Define acquisition function (UCB with beta=1e6)\n",
    "    UCB = UpperConfidenceBound(model, beta=beta)\n",
    "\n",
    "    # Optimize acquisition function\n",
    "    next_point, acq_value = optimize_acqf_discrete(\n",
    "        acq_function=UCB,\n",
    "        choices=candidates,\n",
    "        q=1,\n",
    "    )\n",
    "\n",
    "    # Plot with next point\n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), next_point, ndim=ndim)  # Squeeze for plotting\n",
    "\n",
    "    # Evaluate next point and update training data\n",
    "    next_value = test_function(next_point, ndim).unsqueeze(-1)  # Add extra dimension\n",
    "    train_X = torch.cat([train_X, next_point])\n",
    "    train_Y = torch.cat([train_Y, next_value])  # Now dimensions match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49526be0",
   "metadata": {},
   "source": [
    "### 3a. iii) Custom mean function 3 - based on the idea of a Quadratic boundary + linear_term + constant - has priors on the terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticBoundaryMean(gpytorch.means.Mean):\n",
    "    def __init__(self, batch_shape=torch.Size()):\n",
    "        super().__init__()\n",
    "\n",
    "        # Original parameters for quadratic term\n",
    "        self.register_parameter(\n",
    "            name=\"raw_center_x\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_center_y\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_scale\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_a\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_b\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_theta\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "\n",
    "        # Weights for different terms\n",
    "        self.register_parameter(\n",
    "            name=\"raw_w1\",  # weight for constant term\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_w2\",  # weight for quadratic term\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_w3\",  # weight for linear term\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "\n",
    "        # Linear term parameters\n",
    "        self.register_parameter(\n",
    "            name=\"raw_slope_x\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_slope_y\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_constant\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "\n",
    "        # Register constraints\n",
    "        self.register_constraint(\"raw_center_x\", Interval(-5.0, 5.0))\n",
    "        self.register_constraint(\"raw_center_y\", Interval(-5.0, 5.0))\n",
    "        self.register_constraint(\"raw_scale\", Positive())\n",
    "        self.register_constraint(\"raw_a\", Positive())\n",
    "        self.register_constraint(\"raw_b\", Positive())\n",
    "        self.register_constraint(\"raw_theta\", Interval(-np.pi, np.pi))\n",
    "        self.register_constraint(\"raw_w1\", Positive())\n",
    "        self.register_constraint(\"raw_w2\", Positive())\n",
    "        self.register_constraint(\"raw_w3\", Positive())\n",
    "        self.register_constraint(\"raw_slope_x\", Interval(-5.0, 5.0))\n",
    "        self.register_constraint(\"raw_slope_y\", Interval(-5.0, 5.0))\n",
    "        self.register_constraint(\"raw_constant\", Interval(-5.0, 5.0))\n",
    "\n",
    "        # Register priors for original parameters\n",
    "        self.register_prior(\n",
    "            \"center_x_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.center_x,\n",
    "            lambda module, value: module._set_center_x(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"center_y_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.center_y,\n",
    "            lambda module, value: module._set_center_y(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"scale_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.scale,\n",
    "            lambda module, value: module._set_scale(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"a_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.a,\n",
    "            lambda module, value: module._set_a(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"b_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.b,\n",
    "            lambda module, value: module._set_b(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"theta_prior\",\n",
    "            NormalPrior(0.0, np.pi/4),\n",
    "            lambda module: module.theta,\n",
    "            lambda module, value: module._set_theta(value)\n",
    "        )\n",
    "\n",
    "        # Register priors for weights\n",
    "        self.register_prior(\n",
    "            \"w1_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.w1,\n",
    "            lambda module, value: module._set_w1(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"w2_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.w2,\n",
    "            lambda module, value: module._set_w2(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"w3_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.w3,\n",
    "            lambda module, value: module._set_w3(value)\n",
    "        )\n",
    "\n",
    "        # Register priors for linear terms\n",
    "        self.register_prior(\n",
    "            \"slope_x_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.slope_x,\n",
    "            lambda module, value: module._set_slope_x(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"slope_y_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.slope_y,\n",
    "            lambda module, value: module._set_slope_y(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"constant_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.constant,\n",
    "            lambda module, value: module._set_constant(value)\n",
    "        )\n",
    "\n",
    "    # Properties for all parameters\n",
    "    @property\n",
    "    def center_x(self):\n",
    "        return self.raw_center_x_constraint.transform(self.raw_center_x)\n",
    "\n",
    "    @property\n",
    "    def center_y(self):\n",
    "        return self.raw_center_y_constraint.transform(self.raw_center_y)\n",
    "\n",
    "    @property\n",
    "    def scale(self):\n",
    "        return self.raw_scale_constraint.transform(self.raw_scale)\n",
    "\n",
    "    @property\n",
    "    def a(self):\n",
    "        return self.raw_a_constraint.transform(self.raw_a)\n",
    "\n",
    "    @property\n",
    "    def b(self):\n",
    "        return self.raw_b_constraint.transform(self.raw_b)\n",
    "\n",
    "    @property\n",
    "    def theta(self):\n",
    "        return self.raw_theta_constraint.transform(self.raw_theta)\n",
    "\n",
    "    @property\n",
    "    def w1(self):\n",
    "        return self.raw_w1_constraint.transform(self.raw_w1)\n",
    "\n",
    "    @property\n",
    "    def w2(self):\n",
    "        return self.raw_w2_constraint.transform(self.raw_w2)\n",
    "\n",
    "    @property\n",
    "    def w3(self):\n",
    "        return self.raw_w3_constraint.transform(self.raw_w3)\n",
    "\n",
    "    @property\n",
    "    def slope_x(self):\n",
    "        return self.raw_slope_x_constraint.transform(self.raw_slope_x)\n",
    "\n",
    "    @property\n",
    "    def slope_y(self):\n",
    "        return self.raw_slope_y_constraint.transform(self.raw_slope_y)\n",
    "\n",
    "    @property\n",
    "    def constant(self):\n",
    "        return self.raw_constant_constraint.transform(self.raw_constant)\n",
    "\n",
    "    # Setters for all parameters\n",
    "    def _set_center_x(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_center_x=self.raw_center_x_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_center_y(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_center_y=self.raw_center_y_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_scale(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_scale=self.raw_scale_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_a(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_a=self.raw_a_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_b(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_b=self.raw_b_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_theta(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_theta=self.raw_theta_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_w1(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_w1=self.raw_w1_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_w2(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_w2=self.raw_w2_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_w3(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_w3=self.raw_w3_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_slope_x(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_slope_x=self.raw_slope_x_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_slope_y(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_slope_y=self.raw_slope_y_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_constant(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_constant=self.raw_constant_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndimension() == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "\n",
    "        x1, x2 = x[..., 0], x[..., 1]\n",
    "        \n",
    "        # Quadratic term\n",
    "        x1_t = x1 - self.center_x\n",
    "        x2_t = x2 - self.center_y\n",
    "        cos_theta = torch.cos(self.theta)\n",
    "        sin_theta = torch.sin(self.theta)\n",
    "        x1_r = x1_t * cos_theta + x2_t * sin_theta\n",
    "        x2_r = -x1_t * sin_theta + x2_t * cos_theta\n",
    "        quad_term = torch.sigmoid(10.0 * ((x1_r/self.a)**2 + (x2_r/self.b)**2 - self.scale))\n",
    "        \n",
    "        # Linear term\n",
    "        linear_term = self.slope_x * x1 + self.slope_y * x2\n",
    "        \n",
    "        # Combine all terms with weights\n",
    "        return (self.w1 * self.constant + \n",
    "                self.w2 * quad_term + \n",
    "                self.w3 * linear_term)\n",
    "        \n",
    "        \n",
    "def plot_mean_function(mean_module, resolution=100):\n",
    "    \"\"\"\n",
    "    Visualize the mean function in 2D and 3D\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Create grid of points\n",
    "    x = np.linspace(-3, 3, resolution)\n",
    "    y = np.linspace(-3, 3, resolution)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    points = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        Z = mean_module(torch.tensor(points, dtype=torch.float32))\n",
    "        Z = Z.reshape(resolution, resolution).numpy()\n",
    "    \n",
    "    # 2D Visualization\n",
    "    plt.subplot(121)\n",
    "    plt.contour(X, Y, Z, levels=20)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Mean Function (2D)\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    \n",
    "    # 3D Visualization\n",
    "    ax = plt.subplot(122, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    plt.colorbar(surf)\n",
    "    ax.set_title(\"Mean Function (3D)\")\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_zlabel(\"f(x)\")\n",
    "    \n",
    "    # Show parameter values\n",
    "    param_text = (f'Parameters:\\nCenter: ({mean_module.center_x.item():.3f}, '\n",
    "                 f'{mean_module.center_y.item():.3f})\\n'\n",
    "                 f'Scale: {mean_module.scale.item():.3f}\\n'\n",
    "                 f'a: {mean_module.a.item():.3f}\\n'\n",
    "                 f'b: {mean_module.b.item():.3f}\\n'\n",
    "                 f'Î¸: {mean_module.theta.item():.3f}')\n",
    "\n",
    "    # plt.text(0.02, 0.98, param_text,\n",
    "    #          transform=plt.gca().transAxes,\n",
    "    #          verticalalignment='top',\n",
    "    #          bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Initialize and visualize\n",
    "mean_module = QuadraticBoundaryMean()\n",
    "plot_mean_function(mean_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e4b36f",
   "metadata": {},
   "source": [
    "#### 3a. iii.a) Train sGP model for custom mean function 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 50\n",
    "n_test = 10000\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim)\n",
    "\n",
    "# # Define priors\n",
    "# lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "# outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "\n",
    "# Conservative/Standard priors\n",
    "# lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 1.0)  # mean = 3.0, variance = 3.0\n",
    "# outputscale_prior = gpytorch.priors.GammaPrior(2.0, 2.0)  # mean = 1.0, variance = 0.5\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1.5, 3.0)        # mean = 0.5, variance = 0.17\n",
    "# Priors for Sparse GP with RBF/Matern kernel\n",
    "lengthscale_prior = gpytorch.priors.GammaPrior(2.0, 4.0)  # mean=0.5, more local variations\n",
    "outputscale_prior = gpytorch.priors.GammaPrior(4.0, 4.0)  # mean=1.0, moderate variance\n",
    "noise_prior = gpytorch.priors.GammaPrior(1.5, 6.0)        # mean=0.25, small noise\n",
    "\n",
    "\n",
    "\n",
    "# Define model components\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "# mean_module = CustomMean(ndim)\n",
    "mean_module = mean_function\n",
    "covar_module = CustomKernel(\n",
    "    ndim,\n",
    "    lengthscale_prior=lengthscale_prior,\n",
    "    outputscale_prior=outputscale_prior\n",
    ")\n",
    "\n",
    "# Initialize and fit model\n",
    "model = CustomGP(train_X, train_Y, mean_module, covar_module, likelihood)\n",
    "mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "plot_step(model, train_X, train_Y.squeeze(-1), ndim=ndim)  # Squeeze for plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9382bb",
   "metadata": {},
   "source": [
    "#### 3a. iii.b) Active learing for custom mean function 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 1\n",
    "n_iterations = 15\n",
    "beta = 1e6### --> higher means more exploration\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim).unsqueeze(-1)  # Add extra dimension here --> so concatenation works fine in the loop\n",
    "\n",
    "# Generate candidate points for discrete optimization\n",
    "n_candidates = 1000\n",
    "candidates = sample_points(ndim, n_candidates)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Define priors\n",
    "    # lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "    # outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "    # noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "    # Conservative/Standard priors\n",
    "    lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 1.0)  # mean = 3.0, variance = 3.0\n",
    "    outputscale_prior = gpytorch.priors.GammaPrior(2.0, 2.0)  # mean = 1.0, variance = 0.5\n",
    "    noise_prior = gpytorch.priors.GammaPrior(1.5, 3.0)        # mean = 0.5, variance = 0.17\n",
    "\n",
    "    # Define model components\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "    # mean_module = CustomMean(ndim)\n",
    "    covar_module = CustomKernel(\n",
    "        ndim,\n",
    "        lengthscale_prior=lengthscale_prior,\n",
    "        outputscale_prior=outputscale_prior\n",
    "    )\n",
    "\n",
    "    # Initialize and fit model\n",
    "    model = CustomGP(train_X, train_Y.squeeze(-1), mean_module, covar_module, likelihood)  # Squeeze here for CustomGP\n",
    "    mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Plot current state\n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), ndim=ndim)  # Squeeze for plotting\n",
    "\n",
    "    # Define acquisition function (UCB with beta=1e6)\n",
    "    UCB = UpperConfidenceBound(model, beta=beta)\n",
    "\n",
    "    # Optimize acquisition function\n",
    "    next_point, acq_value = optimize_acqf_discrete(\n",
    "        acq_function=UCB,\n",
    "        choices=candidates,\n",
    "        q=1,\n",
    "    )\n",
    "\n",
    "    # Plot with next point\n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), next_point, ndim=ndim)  # Squeeze for plotting\n",
    "\n",
    "    # Evaluate next point and update training data\n",
    "    next_value = test_function(next_point, ndim).unsqueeze(-1)  # Add extra dimension\n",
    "    train_X = torch.cat([train_X, next_point])\n",
    "    train_Y = torch.cat([train_Y, next_value])  # Now dimensions match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab24a1",
   "metadata": {},
   "source": [
    "### 3a. iv) Custom mean function 4 - trying fourier basis as a mean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleMean(gpytorch.means.Mean):\n",
    "    def __init__(self, num_fourier_terms=3, num_polynomial_terms=3, batch_shape=torch.Size()):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_fourier_terms = num_fourier_terms\n",
    "        self.num_polynomial_terms = num_polynomial_terms\n",
    "\n",
    "        # Register Fourier frequencies\n",
    "        self.register_parameter(\n",
    "            name=\"raw_frequencies\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(num_fourier_terms))\n",
    "        )\n",
    "\n",
    "        # Register Fourier weights (sine and cosine terms)\n",
    "        self.register_parameter(\n",
    "            name=\"raw_fourier_weights_sin\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(num_fourier_terms))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_fourier_weights_cos\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(num_fourier_terms))\n",
    "        )\n",
    "\n",
    "        # Register polynomial weights\n",
    "        self.register_parameter(\n",
    "            name=\"raw_poly_weights\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(num_polynomial_terms))\n",
    "        )\n",
    "\n",
    "        # Register constant term\n",
    "        self.register_parameter(\n",
    "            name=\"raw_constant\",\n",
    "            parameter=torch.nn.Parameter(torch.zeros(1))\n",
    "        )\n",
    "\n",
    "        # Register constraints\n",
    "        self.register_constraint(\"raw_frequencies\", Positive())\n",
    "        self.register_constraint(\"raw_fourier_weights_sin\", Interval(-5.0, 5.0))\n",
    "        self.register_constraint(\"raw_fourier_weights_cos\", Interval(-5.0, 5.0))\n",
    "        self.register_constraint(\"raw_poly_weights\", Interval(-5.0, 5.0))\n",
    "        self.register_constraint(\"raw_constant\", Interval(-5.0, 5.0))\n",
    "\n",
    "        # Register priors\n",
    "        # Frequencies prior (log-normal to ensure positivity and reasonable spread)\n",
    "        self.register_prior(\n",
    "            \"frequencies_prior\",\n",
    "            LogNormalPrior(0.0, 1.0),\n",
    "            lambda module: module.frequencies,\n",
    "            lambda module, value: module._set_frequencies(value)\n",
    "        )\n",
    "\n",
    "        # Fourier weights priors (normal distribution)\n",
    "        self.register_prior(\n",
    "            \"fourier_weights_sin_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.fourier_weights_sin,\n",
    "            lambda module, value: module._set_fourier_weights_sin(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"fourier_weights_cos_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.fourier_weights_cos,\n",
    "            lambda module, value: module._set_fourier_weights_cos(value)\n",
    "        )\n",
    "\n",
    "        # Polynomial weights prior (student-t for robustness)\n",
    "        self.register_prior(\n",
    "            \"poly_weights_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.poly_weights,\n",
    "            lambda module, value: module._set_poly_weights(value)\n",
    "        )\n",
    "\n",
    "        # Constant term prior\n",
    "        self.register_prior(\n",
    "            \"constant_prior\",\n",
    "            NormalPrior(0.0, 1.0),\n",
    "            lambda module: module.constant,\n",
    "            lambda module, value: module._set_constant(value)\n",
    "        )\n",
    "\n",
    "    # Properties\n",
    "    @property\n",
    "    def frequencies(self):\n",
    "        return self.raw_frequencies_constraint.transform(self.raw_frequencies)\n",
    "\n",
    "    @property\n",
    "    def fourier_weights_sin(self):\n",
    "        return self.raw_fourier_weights_sin_constraint.transform(self.raw_fourier_weights_sin)\n",
    "\n",
    "    @property\n",
    "    def fourier_weights_cos(self):\n",
    "        return self.raw_fourier_weights_cos_constraint.transform(self.raw_fourier_weights_cos)\n",
    "\n",
    "    @property\n",
    "    def poly_weights(self):\n",
    "        return self.raw_poly_weights_constraint.transform(self.raw_poly_weights)\n",
    "\n",
    "    @property\n",
    "    def constant(self):\n",
    "        return self.raw_constant_constraint.transform(self.raw_constant)\n",
    "\n",
    "    # Setters\n",
    "    def _set_frequencies(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_frequencies=self.raw_frequencies_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_fourier_weights_sin(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_fourier_weights_sin=self.raw_fourier_weights_sin_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_fourier_weights_cos(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_fourier_weights_cos=self.raw_fourier_weights_cos_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_poly_weights(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_poly_weights=self.raw_poly_weights_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_constant(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_constant=self.raw_constant_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndimension() == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "\n",
    "        x1, x2 = x[..., 0], x[..., 1]\n",
    "        r = torch.sqrt(x1**2 + x2**2)\n",
    "        theta = torch.atan2(x2, x1)\n",
    "\n",
    "        # Fourier terms\n",
    "        fourier_basis = torch.zeros_like(r)\n",
    "        for i in range(self.num_fourier_terms):\n",
    "            fourier_basis += (self.fourier_weights_sin[i] * torch.sin(self.frequencies[i] * r) +\n",
    "                            self.fourier_weights_cos[i] * torch.cos(self.frequencies[i] * r))\n",
    "\n",
    "        # Polynomial terms\n",
    "        poly_basis = torch.zeros_like(r)\n",
    "        for i in range(self.num_polynomial_terms):\n",
    "            poly_basis += self.poly_weights[i] * r**i\n",
    "\n",
    "        return self.constant + fourier_basis + poly_basis\n",
    "\n",
    "def plot_flexible_mean(mean_module, x_range=(-5, 5), y_range=(-5, 5), resolution=100):\n",
    "    \"\"\"\n",
    "    Visualize the flexible mean function\n",
    "    \"\"\"\n",
    "    x = np.linspace(x_range[0], x_range[1], resolution)\n",
    "    y = np.linspace(y_range[0], y_range[1], resolution)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    points = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        Z = mean_module(torch.tensor(points, dtype=torch.float32))\n",
    "        Z = Z.reshape(resolution, resolution).numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 2D contour plot\n",
    "    plt.subplot(121)\n",
    "    plt.contour(X, Y, Z, levels=20)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Mean Function (2D)\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    \n",
    "    # 3D surface plot\n",
    "    ax = fig.add_subplot(122, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    plt.colorbar(surf)\n",
    "    ax.set_title(\"Mean Function (3D)\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"f(x, y)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create and visualize\n",
    "mean_module = FlexibleMean(num_fourier_terms=3, num_polynomial_terms=3)\n",
    "plot_flexible_mean(mean_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893af1cc",
   "metadata": {},
   "source": [
    "#### 3a. iv.a) Train sGP model for custom mean function 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee832ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 50\n",
    "n_test = 10000\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim)\n",
    "\n",
    "# # Define priors\n",
    "# lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "# outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "\n",
    "# Conservative/Standard priors\n",
    "# lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 1.0)  # mean = 3.0, variance = 3.0\n",
    "# outputscale_prior = gpytorch.priors.GammaPrior(2.0, 2.0)  # mean = 1.0, variance = 0.5\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1.5, 3.0)        # mean = 0.5, variance = 0.17\n",
    "# Priors for Sparse GP with RBF/Matern kernel\n",
    "lengthscale_prior = gpytorch.priors.GammaPrior(2.0, 4.0)  # mean=0.5, more local variations\n",
    "outputscale_prior = gpytorch.priors.GammaPrior(4.0, 4.0)  # mean=1.0, moderate variance\n",
    "noise_prior = gpytorch.priors.GammaPrior(1.5, 6.0)        # mean=0.25, small noise\n",
    "\n",
    "\n",
    "\n",
    "# Define model components\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "# mean_module = CustomMean(ndim)\n",
    "mean_module = mean_function\n",
    "covar_module = CustomKernel(\n",
    "    ndim,\n",
    "    lengthscale_prior=lengthscale_prior,\n",
    "    outputscale_prior=outputscale_prior\n",
    ")\n",
    "\n",
    "# Initialize and fit model\n",
    "model = CustomGP(train_X, train_Y, mean_module, covar_module, likelihood)\n",
    "mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "plot_step(model, train_X, train_Y.squeeze(-1), ndim=ndim)  # Squeeze for plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2940aa80",
   "metadata": {},
   "source": [
    "#### 3a. iv.b) Active learing for custom mean function 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 50\n",
    "n_test = 10000\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim)\n",
    "\n",
    "# # Define priors\n",
    "# lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "# outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "\n",
    "# Conservative/Standard priors\n",
    "# lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 1.0)  # mean = 3.0, variance = 3.0\n",
    "# outputscale_prior = gpytorch.priors.GammaPrior(2.0, 2.0)  # mean = 1.0, variance = 0.5\n",
    "# noise_prior = gpytorch.priors.GammaPrior(1.5, 3.0)        # mean = 0.5, variance = 0.17\n",
    "# Priors for Sparse GP with RBF/Matern kernel\n",
    "lengthscale_prior = gpytorch.priors.GammaPrior(2.0, 4.0)  # mean=0.5, more local variations\n",
    "outputscale_prior = gpytorch.priors.GammaPrior(4.0, 4.0)  # mean=1.0, moderate variance\n",
    "noise_prior = gpytorch.priors.GammaPrior(1.5, 6.0)        # mean=0.25, small noise\n",
    "\n",
    "\n",
    "\n",
    "# Define model components\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "# mean_module = CustomMean(ndim)\n",
    "mean_module = QuadraticBoundaryMean()\n",
    "covar_module = CustomKernel(\n",
    "    ndim,\n",
    "    lengthscale_prior=lengthscale_prior,\n",
    "    outputscale_prior=outputscale_prior\n",
    ")\n",
    "\n",
    "# Initialize and fit model\n",
    "model = CustomGP(train_X, train_Y, mean_module, covar_module, likelihood)\n",
    "mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "plot_step(model, train_X, train_Y.squeeze(-1), ndim=ndim)  # Squeeze for plotting\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boactivemat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
