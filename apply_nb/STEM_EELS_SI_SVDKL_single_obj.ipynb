{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/utkarshp1161/Active-learning-in-microscopy/blob/apply/apply_nb/STEM_EELS_SI_SVDKL_single_obj.ipynb)\n",
    "\n",
    "# Single-objective Active learning using DigitalTwin microscope:applied to EELS spectrum image data. [Adapted from - notebook link](https://github.com/utkarshp1161/Active-learning-in-microscopy/blob/main/notebooks/single_objective_BO_SVDKL.ipynb)\n",
    "\n",
    "Prepared by [Utkarsh Pratiush](https://github.com/utkarshp1161)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install modules and start DigitalTwin microscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install\n",
    "!pip install botorch==0.12.0\n",
    "!pip install gpytorch==1.13\n",
    "!pip install git+https://github.com/pycroscopy/DTMicroscope.git\n",
    "!pip install h5py\n",
    "!pip install sidpy\n",
    "!pip install -q pyro5\n",
    "!pip install -q scifireaders\n",
    "!pip install -q pynsid\n",
    "!pip install pytemlib\n",
    "\n",
    "## start dtmic\n",
    "!run_server_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. eels data - credits : Austin Houston and Utkarsh Pratiush\n",
    "\n",
    "- Sample : Ag-SiN - collected on March 6th 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1U7yTAe3Mub4tKnG6FQctyfoq2JKQ06S7 \n",
    "\n",
    "import h5py\n",
    "import sidpy\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "from datetime import datetime\n",
    "import Pyro5.api\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pyNSID\n",
    "import SciFiReaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single Objective BO with DKL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. DKL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "from botorch.posteriors.gpytorch import GPyTorchPosterior\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution, VariationalStrategy\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import Tuple, Optional, Dict, Union, List\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Simple ConvNet for feature extraction\n",
    "class ConvNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels=1, output_dim=32):\n",
    "        super(ConvNetFeatureExtractor, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.output_dim = output_dim\n",
    "        self.fc = None  # Placeholder for the fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3: # TODO: hacky way to make sure botorch acquisition function works\n",
    "            # flatten\n",
    "            batch_size, channel, mn = x.shape[0], x.shape[1] , x.shape[2]\n",
    "            d = math.sqrt(mn)      ## TODO: what if mn is not a perfect square?\n",
    "            x = x.reshape(int(batch_size), int(channel), int(d), int(d))\n",
    "        # Pass through the convolutional layers\n",
    "        x = self.conv_layers(x)\n",
    "\n",
    "\n",
    "        # If the fully connected layer is not defined yet, initialize it dynamically******************key\n",
    "        if self.fc is None:\n",
    "            flattened_size = x.view(x.size(0), -1).size(1)\n",
    "            device = x.device# TODO: better way to handle device\n",
    "            self.fc = nn.Linear(flattened_size, self.output_dim).to(device)  # Create fc layer on the correct device\n",
    "\n",
    "        # Flatten for fully connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# GP model with deep kernel using ConvNet feature extractor\n",
    "class GPModelDKL(ApproximateGP):\n",
    "    def __init__(self, inducing_points, likelihood, feature_extractor=None):\n",
    "        if feature_extractor is None:\n",
    "            feature_extractor = ConvNetFeatureExtractor(\n",
    "                input_channels=1,  # Set according to your image channels\n",
    "                output_dim=32      # Set as per the final feature dimension\n",
    "            ).to(inducing_points.device)\n",
    "        else:\n",
    "            feature_extractor = feature_extractor.to(inducing_points.device)\n",
    "\n",
    "        # Transform inducing points with ConvNet\n",
    "        inducing_points = feature_extractor(inducing_points)\n",
    "\n",
    "        # Variational setup\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            inducing_points.size(0)\n",
    "        )\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "\n",
    "        super(GPModelDKL, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        self.num_outputs = 1  # must be one\n",
    "        self.likelihood = likelihood\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, x, use_feature_extractor=True, *args, **kwargs):\n",
    "        ## TODO: to make it compatible with botorch acquisition function we need it to make patches internally from flattened patches\n",
    "        if use_feature_extractor:\n",
    "            if len(x.shape) == 3:\n",
    "                # flatten\n",
    "                batch_size, channel, mn = x.shape[0], x.shape[1] , x.shape[2]\n",
    "                d = math.sqrt(mn)      ## TODO: what if mn is not a perfect square?\n",
    "                x = x.reshape(int(batch_size), int(channel), int(d), int(d))\n",
    "            x = self.feature_extractor(x)\n",
    "        return super().__call__(x, *args, **kwargs)\n",
    "\n",
    "    def posterior(self, X, output_indices=None, observation_noise=False, *args, **kwargs) -> GPyTorchPosterior:\n",
    "        self.eval()\n",
    "        self.likelihood.eval()\n",
    "        dist = self.likelihood(self(X))\n",
    "        return GPyTorchPosterior(dist)\n",
    "\n",
    "    @property\n",
    "    def hparam_dict(self):\n",
    "        return {\n",
    "            \"likelihood.noise\": self.likelihood.noise.item(),\n",
    "            \"covar_module.base_kernel.outputscale\": self.covar_module.base_kernel.outputscale.item(),\n",
    "            \"mean_module.constant\": self.mean_module.constant.item(),\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Utility F:n's - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data : np.ndarray) -> np.ndarray:  # Expected data type: torch.Tensor\n",
    "    \"\"\"Normalize data to the [0, 1] range.\"\"\"\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "\n",
    "def numpy_to_torch_for_conv(np_array) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts a NumPy array of shape (batch_size, a, b) to a PyTorch tensor\n",
    "    with shape (batch_size, 1, a, b) for neural network use.\n",
    "\n",
    "    Parameters:\n",
    "        np_array (np.ndarray): Input NumPy array of shape (batch_size, a, b).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Converted PyTorch tensor of shape (batch_size, 1, a, b).\n",
    "    \"\"\"\n",
    "    # Check if input is a numpy array\n",
    "    if not isinstance(np_array, np.ndarray):\n",
    "        raise TypeError(\"Input must be a NumPy array.\")\n",
    "\n",
    "    # Convert to PyTorch tensor and add a channel dimension\n",
    "    tensor = torch.from_numpy(np_array).float()  # Convert to float tensor\n",
    "    tensor = tensor.unsqueeze(1)  # Add a channel dimension at index 1\n",
    "\n",
    "    return tensor\n",
    "\n",
    "\n",
    "######################atomai utils####################################\n",
    "#Credits Maxim Ziatdinov (https://github.com/ziatdinovmax): https://github.com/pycroscopy/atomai/blob/8db3e944cd9ece68c33c8e3fcca3ef3ce9a111ea/atomai/utils/img.py#L522\n",
    "\n",
    "def get_coord_grid(imgdata: np.ndarray, step: int,\n",
    "                   return_dict: bool = True\n",
    "                   ) -> Union[np.ndarray, Dict[int, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Generate a square coordinate grid for every image in a stack. Returns coordinates\n",
    "    in a dictionary format (same format as generated by atomnet.predictor)\n",
    "    that can be used as an input for utility functions extracting subimages\n",
    "    and atomstat.imlocal class\n",
    "\n",
    "    Args:\n",
    "        imgdata (numpy array): 2D or 3D numpy array\n",
    "        step (int): distance between grid points\n",
    "        return_dict (bool): returns coordiantes as a dictionary (same format as atomnet.predictor)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary or numpy array with coordinates\n",
    "    \"\"\"\n",
    "    if np.ndim(imgdata) == 2:\n",
    "        imgdata = np.expand_dims(imgdata, axis=0)\n",
    "    coord = []\n",
    "    for i in range(0, imgdata.shape[1], step):\n",
    "        for j in range(0, imgdata.shape[2], step):\n",
    "            coord.append(np.array([i, j]))\n",
    "    coord = np.array(coord)\n",
    "    if return_dict:\n",
    "        coord = np.concatenate((coord, np.zeros((coord.shape[0], 1))), axis=-1)\n",
    "        coordinates_dict = {i: coord for i in range(imgdata.shape[0])}\n",
    "        return coordinates_dict\n",
    "    coordinates = [coord for _ in range(imgdata.shape[0])]\n",
    "    return np.concatenate(coordinates, axis=0)\n",
    "\n",
    "def get_imgstack(imgdata: np.ndarray,\n",
    "                 coord: np.ndarray,\n",
    "                 r: int) -> Tuple[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts subimages centered at specified coordinates\n",
    "    for a single image\n",
    "\n",
    "    Args:\n",
    "        imgdata (3D numpy array):\n",
    "            Prediction of a neural network with dimensions\n",
    "            :math:`height \\\\times width \\\\times n channels`\n",
    "        coord (N x 2 numpy array):\n",
    "            (x, y) coordinates\n",
    "        r (int):\n",
    "            Window size\n",
    "\n",
    "    Returns:\n",
    "        2-element tuple containing\n",
    "\n",
    "        - Stack of subimages\n",
    "        - (x, y) coordinates of their centers\n",
    "    \"\"\"\n",
    "    img_cr_all = []\n",
    "    com = []\n",
    "    for c in coord:\n",
    "        cx = int(np.around(c[0]))\n",
    "        cy = int(np.around(c[1]))\n",
    "        if r % 2 != 0:\n",
    "            img_cr = np.copy(\n",
    "                imgdata[cx-r//2:cx+r//2+1,\n",
    "                        cy-r//2:cy+r//2+1])\n",
    "        else:\n",
    "            img_cr = np.copy(\n",
    "                imgdata[cx-r//2:cx+r//2,\n",
    "                        cy-r//2:cy+r//2])\n",
    "        if img_cr.shape[0:2] == (int(r), int(r)) and not np.isnan(img_cr).any():\n",
    "            img_cr_all.append(img_cr[None, ...])\n",
    "            com.append(c[None, ...])\n",
    "    if len(img_cr_all) == 0:\n",
    "        return None, None\n",
    "    img_cr_all = np.concatenate(img_cr_all, axis=0)\n",
    "    com = np.concatenate(com, axis=0)\n",
    "    return img_cr_all, com\n",
    "\n",
    "def extract_subimages(imgdata: np.ndarray,\n",
    "                      coordinates: Union[Dict[int, np.ndarray], np.ndarray],\n",
    "                      window_size: int, coord_class: int = 0) -> Tuple[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts subimages centered at certain atom class/type\n",
    "    (usually from a neural network output)\n",
    "\n",
    "    Args:\n",
    "        imgdata (numpy array):\n",
    "            4D stack of images (n, height, width, channel).\n",
    "            It is also possible to pass a single 2D image.\n",
    "        coordinates (dict or N x 2 numpy arry): Prediction from atomnet.locator\n",
    "            (can be from other source but must be in the same format)\n",
    "            Each element is a :math:`N \\\\times 3` numpy array,\n",
    "            where *N* is a number of detected atoms/defects,\n",
    "            the first 2 columns are *xy* coordinates\n",
    "            and the third columns is class (starts with 0).\n",
    "            It is also possible to pass N x 2 numpy array if the corresponding\n",
    "            imgdata is a single 2D image.\n",
    "        window_size (int):\n",
    "            Side of the square for subimage cropping\n",
    "        coord_class (int):\n",
    "            Class of atoms/defects around around which the subimages\n",
    "            will be cropped (3rd column in the atomnet.locator output)\n",
    "\n",
    "    Returns:\n",
    "        3-element tuple containing\n",
    "\n",
    "        - stack of subimages,\n",
    "        - (x, y) coordinates of their centers,\n",
    "        - frame number associated with each subimage\n",
    "    \"\"\"\n",
    "    if isinstance(coordinates, np.ndarray):\n",
    "        coordinates = np.concatenate((\n",
    "            coordinates, np.zeros((coordinates.shape[0], 1))), axis=-1)\n",
    "        coordinates = {0: coordinates}\n",
    "    if np.ndim(imgdata) == 2:\n",
    "        imgdata = imgdata[None, ..., None]\n",
    "    subimages_all, com_all, frames_all = [], [], []\n",
    "    for i, (img, coord) in enumerate(\n",
    "            zip(imgdata, coordinates.values())):\n",
    "        coord_i = coord[np.where(coord[:, 2] == coord_class)][:, :2]\n",
    "        stack_i, com_i = get_imgstack(img, coord_i, window_size)\n",
    "        if stack_i is None:\n",
    "            continue\n",
    "        subimages_all.append(stack_i)\n",
    "        com_all.append(com_i)\n",
    "        frames_all.append(np.ones(len(com_i), int) * i)\n",
    "    if len(subimages_all) > 0:\n",
    "        subimages_all = np.concatenate(subimages_all, axis=0)\n",
    "        com_all = np.concatenate(com_all, axis=0)\n",
    "        frames_all = np.concatenate(frames_all, axis=0)\n",
    "    return subimages_all, com_all, frames_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Utility F:n's - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*********************************DTmic specific functions starts **********************************************#\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def black_box(index, indices_all, e1a, e1b) -> float:\n",
    "    \"\"\"\n",
    "    Black box function that returns a target score simulates the blackbox function\n",
    "    \"\"\"\n",
    "\n",
    "    e_start,e_end = e1a, e1b\n",
    "    array_list, shape, dtype = mic_server.get_point_data(\n",
    "        spectrum_image_index=\"Channel_001\",\n",
    "        x=int(indices_all[index, 0]),######### TODO: check if x anf y needs to be flipped\n",
    "        y=int(indices_all[index, 1])\n",
    "    )\n",
    "    spectrum = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "    score = spectrum[e_start:e_end].sum()\n",
    "\n",
    "\n",
    "    return score\n",
    "\n",
    "def black_box_loop_height(index, indices_all, e1a, e1b) -> float:\n",
    "    \"\"\"\n",
    "    Black box function that returns a target score simulates the blackbox function\n",
    "    \"\"\"\n",
    "\n",
    "    e_start,e_end = e1a, e1b\n",
    "    array_list, shape, dtype = mic_server.get_point_data(\n",
    "        spectrum_image_index=\"Channel_001\",\n",
    "        x=int(indices_all[index, 0]),######### TODO: check if x anf y needs to be flipped\n",
    "        y=int(indices_all[index, 1])\n",
    "    )\n",
    "    spectrum = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "\n",
    "    def loop_height(raw_spec, cycle):\n",
    "        raw_spec_len = len(raw_spec)\n",
    "        cycle_len = int(raw_spec_len / cycle)\n",
    "        half_len = int(cycle_len / 2)\n",
    "        q_len = int(cycle_len / 4)\n",
    "        loop_top, loop_bottom = [], []\n",
    "        loop_top.append(raw_spec[q_len : q_len + half_len])\n",
    "        loop_top.append(raw_spec[q_len + 2*half_len : q_len + 3*half_len])\n",
    "        loop_top.append(raw_spec[q_len + 4*half_len : 2*q_len + 4*half_len])\n",
    "        loop_bottom.append(raw_spec[:q_len])\n",
    "        loop_bottom.append(raw_spec[q_len + half_len: q_len + 2*half_len])\n",
    "        loop_bottom.append(raw_spec[q_len + 3*half_len: q_len + 4*half_len])\n",
    "        loop_top = np.concatenate(loop_top)\n",
    "        loop_bottom = np.concatenate(loop_bottom)\n",
    "        return np.max(loop_top) - np.min(loop_bottom)\n",
    "\n",
    "    score = loop_height(raw_spec = spectrum, cycle = 3)# TODO: hard coded cycle now\n",
    "\n",
    "\n",
    "\n",
    "    return score\n",
    "\n",
    "def black_box_loop_area(index, indices_all, e1a, e1b) -> float:\n",
    "    \"\"\"\n",
    "    Black box function that returns a target score simulates the blackbox function\n",
    "    \"\"\"\n",
    "\n",
    "    e_start,e_end = e1a, e1b\n",
    "    array_list, shape, dtype = mic_server.get_point_data(\n",
    "        spectrum_image_index=\"Channel_001\",\n",
    "        x=int(indices_all[index, 0]),######### TODO: check if x anf y needs to be flipped\n",
    "        y=int(indices_all[index, 1])\n",
    "    )\n",
    "    spectrum = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "\n",
    "    def loop_area (raw_spec, cycle) :\n",
    "        raw_spec_len = len(raw_spec)\n",
    "        cycle_len = int(raw_spec_len / cycle)\n",
    "        half_len = int(cycle_len / 2)\n",
    "        q_len = int(cycle_len / 4)\n",
    "        loop_top, loop_bottom = [], []\n",
    "        loop_top.append(raw_spec[q_len : q_len + half_len])\n",
    "        loop_top.append(raw_spec[q_len + 2*half_len : q_len + 3*half_len])\n",
    "        loop_top.append(raw_spec[q_len + 4*half_len : 2*q_len + 4*half_len])\n",
    "        loop_bottom.append(raw_spec[:q_len])\n",
    "        loop_bottom.append(raw_spec[q_len + half_len: q_len + 2*half_len])\n",
    "        loop_bottom.append(raw_spec[q_len + 3*half_len: q_len + 4*half_len])\n",
    "        loop_top = np.concatenate(loop_top)\n",
    "        loop_bottom = np.concatenate(loop_bottom)\n",
    "        return np.abs(np.sum(loop_top)-np.sum(loop_bottom))\n",
    "\n",
    "    score = loop_area(raw_spec = spectrum, cycle = 3)# TODO: hard coded cycle now\n",
    "\n",
    "\n",
    "\n",
    "    return score\n",
    "\n",
    "def black_box_positive_nucleation_bias(index, indices_all, e1a, e1b) -> float:\n",
    "    \"\"\"\n",
    "    Black box function that returns a target score simulates the blackbox function\n",
    "    \"\"\"\n",
    "\n",
    "    e_start,e_end = e1a, e1b\n",
    "    array_list, shape, dtype = mic_server.get_point_data(\n",
    "        spectrum_image_index=\"Channel_001\",\n",
    "        x=int(indices_all[index, 0]),######### TODO: check if x anf y needs to be flipped\n",
    "        y=int(indices_all[index, 1])\n",
    "    )\n",
    "    spectrum = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "\n",
    "    def positive_nucleation_bias(raw_spec, cycle):\n",
    "        raw_spec_len = len(raw_spec)\n",
    "        cycle_len = int(raw_spec_len / cycle)\n",
    "        half_len = int(cycle_len / 2)\n",
    "        q_len = int(cycle_len / 4)\n",
    "        loop_top, loop_bottom = [], []\n",
    "        loop_top.append(raw_spec[q_len : q_len + half_len])\n",
    "        loop_top.append(raw_spec[q_len + 2*half_len : q_len + 3*half_len])\n",
    "        loop_top.append(raw_spec[q_len + 4*half_len : 2*q_len + 4*half_len])\n",
    "        loop_bottom.append(raw_spec[:q_len])\n",
    "        loop_bottom.append(raw_spec[q_len + half_len: q_len + 2*half_len])\n",
    "        loop_bottom.append(raw_spec[q_len + 3*half_len: q_len + 4*half_len])\n",
    "        loop_top = np.concatenate(loop_top)\n",
    "        loop_bottom = np.concatenate(loop_bottom)\n",
    "        return np.mean(loop_top) - np.mean(loop_bottom)\n",
    "\n",
    "    score = positive_nucleation_bias(raw_spec = spectrum, cycle = 3)# TODO: hard coded cycle now\n",
    "\n",
    "\n",
    "    return score\n",
    "\n",
    "def black_box_negative_nucleation_bias(index, indices_all, e1a, e1b) -> float:\n",
    "    \"\"\"\n",
    "    Black box function that returns a target score simulates the blackbox function\n",
    "    \"\"\"\n",
    "\n",
    "    e_start,e_end = e1a, e1b\n",
    "    array_list, shape, dtype = mic_server.get_point_data(\n",
    "        spectrum_image_index=\"Channel_001\",\n",
    "        x=int(indices_all[index, 0]),######### TODO: check if x anf y needs to be flipped\n",
    "        y=int(indices_all[index, 1])\n",
    "    )\n",
    "    spectrum = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "\n",
    "    def negative_nucleation_bias(raw_spec, cycle):\n",
    "        raw_spec_len = len(raw_spec)\n",
    "        cycle_len = int(raw_spec_len / cycle)\n",
    "        half_len = int(cycle_len / 2)\n",
    "        q_len = int(cycle_len / 4)\n",
    "        loop_top, loop_bottom = [], []\n",
    "        loop_top.append(raw_spec[q_len : q_len + half_len])\n",
    "        loop_top.append(raw_spec[q_len + 2*half_len : q_len + 3*half_len])\n",
    "        loop_top.append(raw_spec[q_len + 4*half_len : 2*q_len + 4*half_len])\n",
    "        loop_bottom.append(raw_spec[:q_len])\n",
    "        loop_bottom.append(raw_spec[q_len + half_len: q_len + 2*half_len])\n",
    "        loop_bottom.append(raw_spec[q_len + 3*half_len: q_len + 4*half_len])\n",
    "        loop_top = np.concatenate(loop_top)\n",
    "        loop_bottom = np.concatenate(loop_bottom)\n",
    "        return np.min(loop_top) - np.max(loop_bottom)\n",
    "\n",
    "    score = negative_nucleation_bias(raw_spec = spectrum, cycle = 3)# TODO: hard coded cycle now\n",
    "\n",
    "\n",
    "\n",
    "    return score\n",
    "\n",
    "## a) evaluations metrics like nlpd, mse ----\n",
    "def calculate_mse(y_true, y_pred):\n",
    "    \"\"\"Calculate Mean Squared Error (MSE)\"\"\"\n",
    "    #Smaller values indicate better predictions.\n",
    "    #Squaring ensures that positive and negative errors don't cancel out.\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse\n",
    "\n",
    "def calculate_nlpd(y_true, y_pred_mean, y_pred_var):\n",
    "    \"\"\"Calculate Negative Log Predictive Density (NLPD)\"\"\"\n",
    "    #NLPD evaluates how well the predicted probability distribution matches the true values.\n",
    "    #Lower NLPD indicates a better match, accounting for both the mean and uncertainty.\n",
    "    nlpd = 0.5 * torch.log(2 * torch.pi * y_pred_var) + 0.5 * ((y_true - y_pred_mean) ** 2 / y_pred_var)\n",
    "    return nlpd.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Utility F:n's - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_scores_for_patches(unacquired_indices, indices_all, e1a, e1b, black_box_fn = black_box, debug = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate the score for each patch using the black_box function.\n",
    "\n",
    "    Parameters:\n",
    "    - patches: Tensor of all data patches.\n",
    "\n",
    "    Returns:\n",
    "    - scores: List of scores for each patch.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for i in unacquired_indices:\n",
    "        score = black_box_fn(i, indices_all, e1a, e1b)  # Calculate score for each patch\n",
    "        scores.append(score)\n",
    "    return torch.tensor(scores)  # Return as a tensor for compatibility\n",
    "\n",
    "def update_acquired(acquired_data, unacquired_indices, selected_indices, indices_all, e1a, e1b, black_box_fn = black_box) -> (np.array, list):\n",
    "    for idx in selected_indices:# TODO: It queries the black box everytime on already acquired points:\n",
    "        acquired_data[idx] = black_box_fn(idx, indices_all, e1a, e1b)\n",
    "    unacquired_indices = [idx for idx in unacquired_indices if idx not in selected_indices]\n",
    "\n",
    "\n",
    "    return acquired_data, unacquired_indices\n",
    "\n",
    "\n",
    "def load_image_and_features(img: np.ndarray , window_size : int) -> (np.ndarray, np.ndarray):\n",
    "    coordinates = get_coord_grid(img, step=1, return_dict=False)\n",
    "    features_all, coords, _ = extract_subimages(img, coordinates, window_size)\n",
    "    features_all = features_all[:, :, :, 0]\n",
    "    coords = np.array(coords, dtype=int)\n",
    "    norm_ = lambda x: (x - x.min()) / x.ptp() # or use:  norm_ = lambda x: (x - np.min(x)) / np.ptp(x) --> numpy-2.0 upgrade\n",
    "    features = norm_(features_all)\n",
    "    return features, coords# shapes (3366, 5, 5) and (3366, 2)\n",
    "\n",
    "\n",
    "def prepare_data_from_microscope(window_size: int) -> (np.ndarray, np.ndarray):\n",
    "    array_list, shape, dtype = mic_server.get_overview_image()\n",
    "    img = np.array(array_list, dtype=dtype).reshape(shape)#\n",
    "    features, indices_all = load_image_and_features(img, window_size)\n",
    "\n",
    "\n",
    "\n",
    "    return img, features, indices_all# shapes (55, 70), (3366, 5, 5) and (3366, 2)\n",
    "\n",
    "def get_spectrum_data(indices, energy_range, channel=\"Channel_001\") -> (np.array, int, int):\n",
    "    array_list, shape, dtype = mic_server.get_spectrum_image(spectrum_image_index=channel)\n",
    "    spectral_img = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "    array_list, shape, dtype = mic_server.get_spectrum_image_e_axis(spectrum_image_index=channel)\n",
    "    E_axis = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "    e_start, e_end = abs(E_axis - energy_range[0]).argmin(), abs(E_axis - energy_range[1]).argmin()\n",
    "    return spectral_img, e_start, e_end\n",
    "\n",
    "def embeddings_and_predictions(model, patches, device=\"cpu\") -> (torch.Tensor, torch.Tensor):\n",
    "    \"\"\"\n",
    "    Get predictions from the trained model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    patches = patches.to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(patches)\n",
    "        embeddings = model.feature_extractor(patches).view(patches.size(0), -1).cpu().numpy()\n",
    "    return predictions, embeddings\n",
    "\n",
    "def train_model(acquired_data, patches, feature_extractor,\n",
    "                device=\"cpu\", num_epochs=50, log_interval=5,\n",
    "                scalarizer_zero=False) -> ApproximateGP:\n",
    "    X_train = torch.stack([patches[idx] for idx in acquired_data]).to(device)\n",
    "    y_train = torch.tensor(list(acquired_data.values()), dtype=torch.float32).to(device)\n",
    "    if scalarizer_zero:\n",
    "        y_train = torch.zeros_like(y_train)\n",
    "\n",
    "    else:\n",
    "        # Normalize y_train\n",
    "\n",
    "        y_train = (y_train - y_train.min()) / (y_train.max() - y_train.min())\n",
    "\n",
    "\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "    inducing_points = X_train[:10]\n",
    "    model = GPModelDKL(inducing_points=inducing_points, likelihood=likelihood, feature_extractor=feature_extractor).to(device)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for epoch in tqdm(range(1, num_epochs + 1), desc=\"Training Progress\"):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "\n",
    "\n",
    "        loss = -mll(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e. Bayesian optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run(config) -> None:\n",
    "    # Extract all configuration variables\n",
    "    seed = config[\"seed\"]\n",
    "    seed_pts = config[\"seed_pts\"]\n",
    "    budget = config[\"budget\"]\n",
    "    in_dir = config[\"in_dir\"]\n",
    "    out_dir_parent = config[\"out_dir_parent\"]\n",
    "    dataset_name = config[\"dataset_name\"]\n",
    "    device = config[\"device\"]\n",
    "    num_epochs = config[\"num_epochs\"]\n",
    "    normalize_data_flag = config[\"normalize_data\"]\n",
    "    window_size = config[\"window_size\"]\n",
    "    scal_pfm = config[\"scal_pfm\"]\n",
    "\n",
    "    energy_range = [0, 1]# TODO: can be confusing as used in eels data - for now ignore for beps\n",
    "\n",
    "    scalarizer_zero = False # TODO: deafult value to zero -- so passed to train_model function --> better way to handel\n",
    "\n",
    "    if scal_pfm is not None:## only for pfm: TODO : find better to accomodiate this\n",
    "        if scal_pfm == \"loop_area\":\n",
    "            black_box_fn = black_box_loop_height\n",
    "\n",
    "        elif scal_pfm == \"loop_height\":\n",
    "            black_box_fn = black_box_loop_height\n",
    "\n",
    "        elif scal_pfm == \"positive_nucleation_bias\":\n",
    "            black_box_fn = black_box_positive_nucleation_bias\n",
    "\n",
    "        elif scal_pfm ==  \"negative_nucleation_bias\":\n",
    "            black_box_fn = black_box_negative_nucleation_bias\n",
    "\n",
    "    else :\n",
    "        black_box_fn = black_box\n",
    "\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    res_dir = Path(out_dir_parent) / f\"Dataset_seed{seed}_{dataset_name}_BO_{seed_pts}_epochs{num_epochs}_budget_{budget}_{scal_pfm}_ws{window_size}_{timestamp}\"\n",
    "    res_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Connect to the microscope server\n",
    "    uri = \"PYRO:microscope.server@localhost:9091\"\n",
    "    global mic_server # TODO: later see better way to do this\n",
    "    mic_server = Pyro5.api.Proxy(uri)\n",
    "\n",
    "    dataset_path = in_dir + \"/\" +  dataset_name\n",
    "    # dataset_path =  dataset_name\n",
    "    ### 2. Download data and register\n",
    "    # !wget https://github.com/pycroscopy/DTMicroscope/raw/utk/data/STEM/SI/test_stem.h5\n",
    "    mic_server.initialize_microscope(\"STEM\")\n",
    "    mic_server.register_data(dataset_path)\n",
    "\n",
    "\n",
    "    # Prepare features and indices from microscope image\n",
    "    img, features, indices_all = prepare_data_from_microscope(window_size=window_size)\n",
    "\n",
    "\n",
    "    ############################################\n",
    "\n",
    "\n",
    "    patches = numpy_to_torch_for_conv(features)\n",
    "\n",
    "    # Set up energy ranges for scalarizer extraction\n",
    "    spectral_img, e1a, e1b = get_spectrum_data(indices_all, energy_range)\n",
    "\n",
    "\n",
    "    patches = patches.to(device)\n",
    "\n",
    "    if normalize_data_flag:\n",
    "        patches = normalize_data(patches)\n",
    "\n",
    "    feature_extractor = ConvNetFeatureExtractor(input_channels=1, output_dim=2).to(device)\n",
    "    acquired_data = {}\n",
    "    unacquired_indices = list(range(len(indices_all)))####### TODO: need to change later to use the indices_all\n",
    "\n",
    "    selected_indices = random.sample(unacquired_indices, seed_pts)\n",
    "\n",
    "    seed_indices = selected_indices\n",
    "    ######### queries spectrum_image\n",
    "    true_scalarizer = calculate_scores_for_patches(unacquired_indices, indices_all, e1a, e1b, black_box_fn=black_box_fn)\n",
    "    true_scalarizer = (true_scalarizer - true_scalarizer.min()) / (true_scalarizer.max() - true_scalarizer.min())######## normalized\n",
    "\n",
    "\n",
    "    ######### queries microscope\n",
    "    acquired_data, unacquired_indices = update_acquired(acquired_data, unacquired_indices, selected_indices, indices_all, e1a, e1b, black_box_fn=black_box_fn)\n",
    "\n",
    "\n",
    "\n",
    "    from botorch.acquisition import LogExpectedImprovement #ExpectedImprovement\n",
    "    mean_y_pred_mean_al = []\n",
    "    mean_y_pred_variance_al = []\n",
    "    mae_list = []\n",
    "    nlpd_list = []\n",
    "    # Start Bayesian Optimization loop\n",
    "    for step in range(budget):\n",
    "\n",
    "        # Train the DKL model\n",
    "        model = train_model(acquired_data, patches, feature_extractor, device=device, num_epochs=num_epochs, scalarizer_zero=scalarizer_zero)\n",
    "        model.eval()\n",
    "\n",
    "\n",
    "        # Wrap the model and likelihood in the BoTorch model ------> Ithink not needed as have approxiamateGP--> check later\n",
    "\n",
    "        # Prepare candidate set (unacquired patches)\n",
    "        candidate_indices = unacquired_indices\n",
    "        \n",
    "        X_candidates = torch.stack([patches[idx] for idx in candidate_indices]).to(device)\n",
    "        X_candidates = X_candidates.reshape(-1, 1, window_size*window_size) # Note this is when using acq f:n directly and not invoking  optimize_acqf_discrete\n",
    "        \n",
    "        y_train = torch.tensor(list(acquired_data.values()), dtype=torch.float32).to(device)\n",
    "        y_train = (y_train - y_train.min()) / (y_train.max() - y_train.min())\n",
    "\n",
    "        acq_func = LogExpectedImprovement(model=model, best_f=y_train.max().to(device))\n",
    "\n",
    "        acq_values = acq_func(X_candidates)\n",
    "        best_idx = torch.argmax(acq_values).item()\n",
    "        selected_candidate = X_candidates[best_idx]\n",
    "        selected_index = candidate_indices[best_idx]\n",
    "        # Map selected tensors back to indices\n",
    "        selected_indices = [selected_index]#### can be multiple indices if batch acquisition\n",
    "\n",
    "        # Update acquired data with new observations\n",
    "        acquired_data, unacquired_indices = update_acquired(acquired_data, unacquired_indices, selected_indices, indices_all, e1a, e1b, black_box_fn=black_box_fn)\n",
    "\n",
    "        print(f\"**************************done BO step {step +1}\")\n",
    "\n",
    "\n",
    "        predictions, embeddings = embeddings_and_predictions(model, patches, device=device)\n",
    "\n",
    "        y_pred_mean = predictions.mean\n",
    "        y_pred_var = predictions.variance\n",
    "\n",
    "\n",
    "        # Calculate MSE and NLPD\n",
    "        mse = calculate_mse(true_scalarizer.cpu(), y_pred_mean.cpu())\n",
    "        mae = np.sqrt(mse)\n",
    "        nlpd = calculate_nlpd(true_scalarizer.cpu(), y_pred_mean.cpu(), y_pred_var.cpu())\n",
    "\n",
    "        # Fill the prediction image with predicted mean values\n",
    "        true_scalarizer_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "        y_pred_mean_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "        y_pred_var_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "        # Fill the prediction image with predicted mean values\n",
    "        for j in range(len(indices_all)):\n",
    "            true_scalarizer_img[indices_all[j][0], indices_all[j][1]] = true_scalarizer[j]\n",
    "            y_pred_mean_img[indices_all[j][0], indices_all[j][1]] = y_pred_mean[j]\n",
    "            y_pred_var_img[indices_all[j][0], indices_all[j][1]] = y_pred_var[j]\n",
    "\n",
    "        # Display the images\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "        im0 = axs[0, 0].imshow(img, cmap='gray')\n",
    "        axs[0, 0].set_title('Original Image with next point selection')\n",
    "        axs[0, 0].scatter([int(indices_all[selected_indices[0]][1])], [int(indices_all[selected_indices[0]][0])], color='yellow', marker='x')\n",
    "        fig.colorbar(im0, ax=axs[0, 0])\n",
    "        \n",
    "        im1 = axs[0, 1].imshow(y_pred_mean_img, cmap='viridis')\n",
    "        axs[0, 1].set_title('Predicted Mean')\n",
    "        fig.colorbar(im1, ax=axs[0, 1])\n",
    "\n",
    "        im2 = axs[1, 0].imshow(y_pred_var_img, cmap='viridis')\n",
    "        axs[1, 0].set_title('Predicted Variance')\n",
    "        fig.colorbar(im2, ax=axs[1, 0])\n",
    "\n",
    "        im3 = axs[1, 1].imshow(true_scalarizer_img, cmap='viridis')\n",
    "        axs[1, 1].set_title('True Scalarizer')\n",
    "        fig.colorbar(im3, ax=axs[1, 1])\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.axis('off')\n",
    "\n",
    "        fig.suptitle(f'MAE: {mae:.4f}, NLPD: {nlpd:.4f}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(res_dir) / f'predictions_MAE: {mae:.4f}, NLPD: {nlpd:.4f}_BO_step{step}.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        # Save predictions as a .pkl file\n",
    "        predictions_data = {\n",
    "            \"true_scalarizer_img\": true_scalarizer_img,\n",
    "            \"y_pred_mean_img\": y_pred_mean_img,\n",
    "            \"y_pred_var_img\": y_pred_var_img,\n",
    "            \"mse\": mse,\n",
    "            \"nlpd\": nlpd,\n",
    "            \"embeddings\": embeddings,\n",
    "        }\n",
    "\n",
    "\n",
    "        with open(Path(res_dir) / f'predictions_BO_step{step}.pkl', 'wb') as f:\n",
    "            pickle.dump(predictions_data, f)\n",
    "\n",
    "\n",
    "        mean_y_pred_mean_al.append(y_pred_mean.mean().cpu())\n",
    "        mean_y_pred_variance_al.append(y_pred_var.mean().cpu())\n",
    "        mae_list.append(mae)\n",
    "        nlpd_list.append(nlpd)\n",
    "\n",
    "        # imshow 4 images: img, pred_mean_img, pred_var_img, true_scal_img\n",
    "\n",
    "\n",
    "    # Save predictions as a .pkl file\n",
    "    Active_learning_statistics = {\n",
    "        \"img\": img,\n",
    "        \"features\": features,\n",
    "        \"indices_all\": np.array(indices_all),\n",
    "        \"seed_indices\": np.array(seed_indices),\n",
    "        \"unacquired_indices\": np.array(unacquired_indices),\n",
    "        \"mean_y_pred_mean_al\": np.array(mean_y_pred_mean_al),\n",
    "        \"mean_y_pred_variance_al\": np.array(mean_y_pred_variance_al),\n",
    "        \"mae\": np.array(mae_list),\n",
    "        \"nlpd\": np.array(nlpd_list)\n",
    "                }\n",
    "\n",
    "    with open(Path(res_dir) / f'Active_learning_statistics.pkl', 'wb') as f:\n",
    "        pickle.dump(Active_learning_statistics, f)\n",
    "\n",
    "\n",
    "    ##############################\n",
    "\n",
    "    predictions_data = Active_learning_statistics\n",
    "    # Extract necessary data\n",
    "    img = np.array(predictions_data[\"img\"])  # Image or grid for background visualization\n",
    "    seed_indices = np.array(predictions_data[\"seed_indices\"])  # Initial sampled indices (referring to positions in indices_all)\n",
    "    unacquired_indices = np.array(predictions_data[\"unacquired_indices\"])  # Remaining indices\n",
    "    indices_all = np.array(predictions_data[\"indices_all\"])  # All possible indices (coordinates)\n",
    "\n",
    "    # Map seed_indices and unacquired_indices to their coordinates in indices_all\n",
    "    seed_coords = indices_all[seed_indices]\n",
    "    unacquired_coords = indices_all[unacquired_indices]\n",
    "\n",
    "    # Calculate acquired indices as the complement of unacquired and seed indices\n",
    "    acquired_indices = np.setdiff1d(np.arange(indices_all.shape[0]), np.union1d(seed_indices, unacquired_indices), assume_unique=True)\n",
    "    acquired_coords = indices_all[acquired_indices]\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Display the image or grid as the background\n",
    "    plt.imshow(img, cmap=\"gray\")#, origin=\"lower\")\n",
    "\n",
    "    # Plot the seed points in blue\n",
    "    plt.scatter(seed_coords[:, 1], seed_coords[:, 0], c=\"b\", label=\"Seed Points\", marker=\"o\")\n",
    "\n",
    "    time_order = np.arange(len(acquired_coords))  # Create a sequence representing time\n",
    "    scatter = plt.scatter(acquired_coords[:, 1], acquired_coords[:, 0], c=time_order, cmap=\"bwr\", label=\"Acquired Points\", marker=\"x\")\n",
    "\n",
    "    # Plot the unacquired points in green\n",
    "    # plt.scatter(unacquired_coords[:, 1], unacquired_coords[:, 0], c=\"g\", label=\"Unacquired Points\", marker=\"+\")\n",
    "\n",
    "    # Set plot labels and legend\n",
    "    plt.xlabel(\"X-axis\")\n",
    "    plt.ylabel(\"Y-axis\")\n",
    "    plt.title(\"Active Learning Trajectory\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    # Add a colorbar and label it as \"Steps\"\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label(\"Steps\")\n",
    "\n",
    "\n",
    "    plt.savefig(Path(res_dir) / \"AL_traj.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # Extract data for learning curve\n",
    "    mean_y_pred_mean_al = np.array(predictions_data[\"mean_y_pred_mean_al\"])\n",
    "    mean_y_pred_variance_al = np.array(predictions_data[\"mean_y_pred_variance_al\"])\n",
    "    mae_list = np.array(predictions_data[\"mae\"])\n",
    "    nlpd_list = np.array(predictions_data[\"nlpd\"])\n",
    "\n",
    "    steps = np.arange(len(mean_y_pred_mean_al))  # Assuming the steps are sequential indices\n",
    "\n",
    "    # Calculate the upper and lower bounds using variance\n",
    "    upper_bound = mean_y_pred_mean_al + np.sqrt(mean_y_pred_variance_al)\n",
    "    lower_bound = mean_y_pred_mean_al - np.sqrt(mean_y_pred_variance_al)\n",
    "\n",
    "    # Plot the learning curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot the mean predictions\n",
    "    plt.plot(steps, mean_y_pred_mean_al, label=\"Mean Prediction\", color=\"blue\", linewidth=2)\n",
    "\n",
    "    # Fill between the upper and lower bounds to represent variance\n",
    "    plt.fill_between(\n",
    "        steps,\n",
    "        lower_bound,\n",
    "        upper_bound,\n",
    "        color=\"blue\",\n",
    "        alpha=0.2,\n",
    "        label=\"Variance (±1 std)\"\n",
    "    )\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Mean Prediction\")\n",
    "    plt.title(\"Learning Curve with Variance\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(Path(res_dir) /\"AL_learning_curve.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(steps, mae_list, color=\"red\", linewidth=2)\n",
    "\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Mean absolute ERROR\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(Path(res_dir) / \"AL_error_curve.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3f. Set parameters and Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"seed\" : 1, # for repeatibility\n",
    "        \"seed_pts\" : 10, # How many points you want to start your BO with?\n",
    "        \"budget\" : 50, # How many experimental budget you have?\n",
    "        \"in_dir\": \"/nfs/home/upratius/scratch_i24/projects/gp_experimetns/GpyDKLBO/in_dir\", # recommended : leave as is\n",
    "        \"out_dir_parent\": \"out\", # recommended : leave as is\n",
    "        \"dataset_name\": \"SiN-Au-Overview.h5\", # name of data to be loaded in DTmicroscope\n",
    "        \"device\": \"cuda\",\n",
    "        \"num_epochs\": 100, # Number of epoch the dkl model trains at each experimental step - Might need tuning based on data\n",
    "        \"normalize_data\": True, \n",
    "        \"window_size\": 16, # For square patches - structure property relationship\n",
    "        \"scal_pfm\": None # What physics interested in? options on this data: \"loop_area\", \"loop_height\", \"positive_nucleation_bias\", \"negative_nucleation_bias\"\n",
    "        }\n",
    "run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
