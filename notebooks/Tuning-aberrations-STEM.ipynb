{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1123ca",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/utkarshp1161/Active-learning-in-microscopy/blob/main/notebooks/Tuning-aberrations-STEM.ipynb)\n",
    "\n",
    "# Goal: Optimizing Electron Microscopy Image Quality through MOBO-Driven Aberration Tuning\n",
    "- Note: If you are not familiar with aberrations or electron Microscope its completely fine\n",
    "    - Treat it like optimizing bunch of paramteres fast to get a good signal (which in this case is image)\n",
    "    - The skill you learn here is useful to apply on your optimization problems\n",
    "    - at the end I have put some suggested things to try as exercise\n",
    "\n",
    "## Recommended: Take a GPU instance in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d0274f",
   "metadata": {},
   "source": [
    "## Credits \n",
    "- Utkarsh and Sergei for this notebook and framing the optimization problem\n",
    "- Gerd and Austin for the simulator \n",
    "    - checkout Austins original github repo here\n",
    "        - https://github.com/AustinHouston/pystemsim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea6ffc",
   "metadata": {},
   "source": [
    "### 1. Install stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install - botorch, gpytorch, abtem, pytemlib\n",
    "!pip install botorch==0.12.0\n",
    "!pip install gpytorch==1.13\n",
    "!pip install abtem\n",
    "!pip install pytemlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a313d0d",
   "metadata": {},
   "source": [
    "### 2. Simulator helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47081204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: This file contains the functions to generate synthetic data for the neural network training.\n",
    "# By Austin Houston\n",
    "# Date: 02/28/2024\n",
    "# Updated: 05/10/2024\n",
    "\n",
    "import dask\n",
    "import numpy as np\n",
    "import random\n",
    "import sidpy\n",
    "import dask.array as da\n",
    "import scipy.special as sp\n",
    "from scipy.ndimage import zoom, gaussian_filter\n",
    "from skimage.draw import disk\n",
    "from ase import Atoms\n",
    "from ase.neighborlist import NeighborList\n",
    "from scipy.fft import fft2, ifft2\n",
    "import pyTEMlib.probe_tools as pt\n",
    "\n",
    "\n",
    "def make_holes(atoms: Atoms, n_holes: int, hole_size: float) -> Atoms:\n",
    "    \"\"\"\n",
    "    Create holes in an Atoms object by deleting atoms around randomly selected positions.\n",
    "\n",
    "    Parameters:\n",
    "    - atoms (ase.Atoms): The input Atoms object.\n",
    "    - n_holes (int): The number of holes to create.\n",
    "    - hole_size (float): The radius of each hole.\n",
    "\n",
    "    Returns:\n",
    "    - ase.Atoms: The modified Atoms object with holes.\n",
    "    \"\"\"\n",
    "    # Step 1: Randomly select n_holes atoms\n",
    "    num_atoms = len(atoms)\n",
    "    selected_indices = random.sample(range(num_atoms), n_holes)\n",
    "\n",
    "    # Step 2: Find and delete atoms within radius hole_size\n",
    "    for index in selected_indices:\n",
    "        # Get the position of the selected atom\n",
    "        pos = atoms[index].position\n",
    "\n",
    "        # Create a NeighborList to find atoms within hole_size\n",
    "        cutoffs = [hole_size / 2] * len(atoms)\n",
    "        nl = NeighborList(cutoffs, self_interaction=False, bothways=True)\n",
    "        nl.update(atoms)\n",
    "\n",
    "        # Find atoms within hole_size around the selected atom\n",
    "        indices, offsets = nl.get_neighbors(index)\n",
    "        indices = indices.tolist()\n",
    "\n",
    "        # Add the selected atom itself to the list of atoms to be deleted\n",
    "        indices.append(index)\n",
    "\n",
    "        # Delete atoms by their indices\n",
    "        atoms = atoms[[atom.index for atom in atoms if atom.index not in indices]]\n",
    "\n",
    "    return atoms\n",
    "\n",
    "def rotate_xtal(xtal, angle):\n",
    "    # pad for worst case and rotate\n",
    "    padded = xtal * (2, 2, 1)\n",
    "    padded.rotate('z', angle, 'com')\n",
    "\n",
    "    # crop to original cell\n",
    "    cell = xtal.cell\n",
    "    positions = padded.get_positions()[:, :2]\n",
    "    inv_cell = np.linalg.inv(cell[:2, :2])\n",
    "    frac = positions @ inv_cell - 0.5\n",
    "    mask = np.all((frac >= 0) & (frac < 1), axis=1)\n",
    "\n",
    "    # creat the new xtal object\n",
    "    xtal_cropped = padded[mask].copy()\n",
    "    xtal_cropped.set_cell(cell, scale_atoms=False)\n",
    "    xtal_cropped.set_scaled_positions(np.hstack([frac[mask], padded.get_scaled_positions()[mask, 2:3]]))\n",
    "\n",
    "    return xtal_cropped\n",
    "\n",
    "def sub_pix_gaussian(size=10, sigma=0.2, dx=0.0, dy=0.0):\n",
    "    # returns sub-pix shifted gaussian\n",
    "    coords = np.arange(size) - (size - 1) / 2.0\n",
    "    x, y = np.meshgrid(coords, coords)\n",
    "    g = np.exp(-(((x + dx) ** 2 + (y + dy) ** 2) / (2 * sigma**2)))\n",
    "    g /= g.max()\n",
    "    return g\n",
    "\n",
    "def create_pseudo_potential(xtal, pixel_size, sigma, bounds, atom_frame=11):\n",
    "    # Create empty image\n",
    "    x_min, x_max = bounds[0], bounds[1]\n",
    "    y_min, y_max = bounds[2], bounds[3]\n",
    "    pixels_x = int((x_max - x_min) / pixel_size)\n",
    "    pixels_y = int((y_max - y_min) / pixel_size)\n",
    "    potential_map = np.zeros((pixels_x, pixels_y))\n",
    "    padding = atom_frame  # to avoid edge effects\n",
    "    potential_map = np.pad(potential_map, padding, mode='constant', constant_values=0.0)\n",
    "\n",
    "    # Map of atomic numbers - i.e. scattering intensity\n",
    "    atomic_numbers = xtal.get_atomic_numbers()\n",
    "    positions = xtal.get_positions()[:, :2]\n",
    "\n",
    "    mask = ((positions[:, 0] >= x_min) & (positions[:, 0] < x_max) & (positions[:, 1] >= y_min) & (positions[:, 1] < y_max))\n",
    "    positions = positions[mask]\n",
    "    atomic_numbers = atomic_numbers[mask]\n",
    "\n",
    "    for pos, atomic_number in zip(positions, atomic_numbers):\n",
    "        x,y = np.round(pos/pixel_size)\n",
    "        dx,dy = pos - np.round(pos)\n",
    "  \n",
    "        single_atom = sub_pix_gaussian(size=atom_frame, sigma=sigma, dx=dx, dy=dy) * atomic_number\n",
    "        potential_map[int(x+padding+dx-padding//2-1):int(x+padding+dx+padding//2),int(y+padding+dy-padding//2-1):int(y+padding+dy+padding//2)] += single_atom\n",
    "    potential_map = potential_map[padding:-padding, padding:-padding]\n",
    "    normalized_map = potential_map / np.max(potential_map)\n",
    "\n",
    "    # make a sidpy dataset\n",
    "    dset = sidpy.Dataset.from_array(normalized_map, name = 'Scattering Potential')\n",
    "    dset.data_type = 'image'\n",
    "    dset.units = 'A.U.'\n",
    "    dset.quantity = 'Scattering cross-section'\n",
    "    dset.set_dimension(0, sidpy.Dimension(pixel_size * np.arange(pixels_x),\n",
    "                        name='x', units='Å', quantity='Length',dimension_type='spatial'))\n",
    "    dset.set_dimension(1, sidpy.Dimension(pixel_size * np.arange(pixels_y),\n",
    "                        name='y', units='Å', quantity='Length',dimension_type='spatial'))\n",
    "\n",
    "    return dset\n",
    "\n",
    "\n",
    "def get_masks(xtal, pixel_size=0.1, radius=3, axis_extent=None, mode='one_hot'):\n",
    "    positions = xtal.get_positions()[:, :2]\n",
    "    atomic_numbers = xtal.get_atomic_numbers()\n",
    "    _, inverse_indices = np.unique(atomic_numbers, return_inverse=True)\n",
    "    atom_ids = inverse_indices + 1  # the background pixels will be labeled as 0\n",
    "    unique_atom_ids = np.unique(atom_ids)\n",
    "\n",
    "    # Determine image size\n",
    "    if axis_extent is not None:\n",
    "        xmin, xmax, ymin, ymax = axis_extent\n",
    "    else:\n",
    "        xmin, xmax = np.min(positions[:, 0]), np.max(positions[:, 0])\n",
    "        ymin, ymax = np.min(positions[:, 1]), np.max(positions[:, 1])\n",
    "    img_height = int((ymax - ymin) / pixel_size)\n",
    "    img_width = int((xmax - xmin) / pixel_size)\n",
    "\n",
    "    master_mask = np.zeros((len(unique_atom_ids), img_height, img_width), dtype=np.uint8)\n",
    "    \n",
    "    def create_mask_for_atom(atom_id):\n",
    "        mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "        atom_mask = (atom_ids == atom_id)\n",
    "        atom_positions = positions[atom_mask]\n",
    "\n",
    "        # Make mask 1 in radius around each atom\n",
    "        for x, y in atom_positions:\n",
    "            x_pixel = int((x - xmin) / pixel_size)\n",
    "            y_pixel = int((y - ymin) / pixel_size)\n",
    "            rr, cc = disk((y_pixel, x_pixel), radius, shape=mask.shape)\n",
    "            mask[rr, cc] = 1\n",
    "        master_mask[atom_id - 1, mask == 1] = 1\n",
    "\n",
    "    # Parallelize the mask creation\n",
    "    tasks = [dask.delayed(create_mask_for_atom)(atom_id) for atom_id in unique_atom_ids]\n",
    "    dask.compute(*tasks)\n",
    "\n",
    "    if mode.lower() == 'one_hot':\n",
    "        num_masks = unique_atom_ids.size + 1  # include background\n",
    "        background_mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "        background_mask[(np.sum(master_mask, axis=0) == 0)] = 1\n",
    "        masks = np.stack([background_mask] + [master_mask[i] for i in range(len(unique_atom_ids))], axis=0)\n",
    "        return masks\n",
    "\n",
    "    elif mode.lower() == 'binary':\n",
    "        sum_masks = np.sum(master_mask, axis=0)\n",
    "        final_mask = np.where(sum_masks > 0, 1, 0)\n",
    "        return final_mask\n",
    "\n",
    "    elif mode.lower() == 'integer':\n",
    "        final_mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "        for i, mask in enumerate(master_mask):\n",
    "            final_mask[mask == 1] = i + 1\n",
    "        return final_mask\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose from 'one_hot', 'binary', or 'integer'\")\n",
    "\n",
    "\n",
    "def airy_disk(potential, resolution = 1.1):\n",
    "    # make grid\n",
    "    size_x = potential.shape[0]\n",
    "    size_y = potential.shape[1]\n",
    "    x = np.arange(size_x) - size_x//2 + 1\n",
    "    y = np.arange(size_y) - size_y//2 + 1\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    rr = np.sqrt(xx**2 + yy**2)\n",
    "\n",
    "    pixel_size = potential.x.slope # Angstrom/pixel\n",
    "    \n",
    "    disk_radius = pixel_size / resolution * 2.5 # Airy disk radius in pixels\n",
    "    # not sure why this 2.5 belonggs in here, but it works\n",
    "\n",
    "    # Calculate the Airy pattern (PSF)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        psf = (2 * sp.j1(disk_radius * rr) / (disk_radius * rr))**2\n",
    "        psf[rr == 0] = 1  # Handling the division by zero at the center\n",
    "\n",
    "    # Normalize the PSF\n",
    "    psf /= np.sum(psf)\n",
    "    \n",
    "    dset = sidpy.Dataset.from_array(psf, name = 'Probe PSF')\n",
    "    dset.data_type = 'image'\n",
    "    dset.units = 'A.U.'\n",
    "    dset.quantity = 'Probability'\n",
    "    dset.set_dimension(0, sidpy.Dimension(pixel_size * np.arange(size_x),\n",
    "                        name='x', units='Å', quantity='Length',dimension_type='spatial'))\n",
    "    dset.set_dimension(1, sidpy.Dimension(pixel_size * np.arange(size_y),\n",
    "                        name='y', units='Å', quantity='Length',dimension_type='spatial'))\n",
    "\n",
    "    return dset\n",
    "\n",
    "def get_probe(ab, potential):\n",
    "    pixel_size = potential.x.slope # Angstrom/pixel\n",
    "    size_x, size_y = potential.shape\n",
    "\n",
    "    probe, A_k, chi  = pt.get_probe(ab, size_x, size_y,  scale = 'mrad', verbose= True)\n",
    "\n",
    "    dset = sidpy.Dataset.from_array(probe, name = 'Probe PSF')\n",
    "    dset.data_type = 'image'\n",
    "    dset.units = 'A.U.'\n",
    "    dset.quantity = 'Probability'\n",
    "    dset.set_dimension(0, sidpy.Dimension(pixel_size * np.arange(size_x),\n",
    "                        name='x', units='Å', quantity='Length',dimension_type='spatial'))\n",
    "    dset.set_dimension(1, sidpy.Dimension(pixel_size * np.arange(size_y),\n",
    "                        name='y', units='Å', quantity='Length',dimension_type='spatial'))\n",
    "\n",
    "    return dset\n",
    "\n",
    "\n",
    "def convolve_kernel(potential, psf):\n",
    "    # Convolve using FFT\n",
    "    psf_shifted = da.fft.ifftshift(psf)\n",
    "    image = da.fft.ifft2(da.fft.fft2(potential) * da.fft.fft2(psf_shifted))\n",
    "    image = da.absolute(image)\n",
    "    image = image - image.min()\n",
    "    image = image / image.max()\n",
    "\n",
    "    size_x, size_y = potential.shape\n",
    "    pixel_size = potential.x.slope # Angstrom/pixel\n",
    "\n",
    "    dset = potential.like_data(image)\n",
    "    dset.units = 'A.U.'\n",
    "    dset.quantity = 'Intensity'\n",
    "    \n",
    "    return dset\n",
    "\n",
    "\n",
    "def poisson_noise(image, counts = 10e8):\n",
    "    # Normalize the image\n",
    "    image = image - image.min()\n",
    "    image = image / image.sum()\n",
    "    noisy_image = np.random.poisson(image * counts)\n",
    "\n",
    "    noisy_image = noisy_image - noisy_image.min()\n",
    "    noisy_image = noisy_image / noisy_image.max()\n",
    "    noisy_image = image.like_data(noisy_image)\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "def lowfreq_noise(image, noise_level=0.1, freq_scale=0.1):\n",
    "    size_x, size_y = image.shape\n",
    "\n",
    "    noise = np.random.normal(0, noise_level, (size_x, size_y))\n",
    "    noise_fft = np.fft.fft2(noise)\n",
    "\n",
    "    # Create a frequency filter that emphasizes low frequencies\n",
    "    x_freqs = np.fft.fftfreq(size_x)\n",
    "    y_freqs = np.fft.fftfreq(size_y)\n",
    "    freq_filter = np.outer(np.exp(-np.square(x_freqs) / (2 * freq_scale**2)),\n",
    "                           np.exp(-np.square(y_freqs) / (2 * freq_scale**2)))\n",
    "\n",
    "    # Apply the frequency filter to the noise in the frequency domain\n",
    "    filtered_noise_fft = noise_fft * freq_filter\n",
    "    low_freq_noise = np.fft.ifft2(filtered_noise_fft).real\n",
    "    noisy_image = image + low_freq_noise\n",
    "    noisy_image = image.like_data(noisy_image)\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "def grid_crop(image_master, crop_size=512, crop_glide=128):\n",
    "    '''\n",
    "    Slices an image into smaller, overlapping square crops.\n",
    "\n",
    "    This function takes a larger image and divides it into smaller, overlapping square segments. \n",
    "    It's useful for processing large images in smaller batches, especially in machine learning applications \n",
    "    where input size is fixed.\n",
    "\n",
    "    Parameters:\n",
    "    - image_master: A NumPy array representing the image to be cropped. \n",
    "                    It should be a 2D array if the image is grayscale, or a 3D array for RGB images.\n",
    "    - crop_size (int, optional): The size of each square crop. Default is 256 pixels.\n",
    "    - crop_glide (int, optional): The stride or glide size for cropping. \n",
    "                                 Determines the overlap between consecutive crops. Default is 128 pixels.\n",
    "\n",
    "    Returns:\n",
    "    - cropped_ims: A NumPy array containing the cropped images. \n",
    "                   The array is 3D, where the first dimension represents the index of the crop, \n",
    "                   and the next two dimensions represent the height and width of the crops.\n",
    "\n",
    "    Note:\n",
    "    - The function assumes the input image is square. Non-square images might lead to unexpected results.\n",
    "    - The return array is of type 'float16' to reduce memory usage, which might affect the precision of pixel values.\n",
    "    '''\n",
    "\n",
    "    n_crops = int((len(image_master) - crop_size)/crop_glide + 1)\n",
    "    cropped_ims = np.zeros((n_crops,n_crops,crop_size,crop_size))\n",
    "\n",
    "    for x in np.arange(n_crops):\n",
    "        for y in np.arange(n_crops):\n",
    "            xx,yy = int(x*crop_glide), int(y*crop_glide)\n",
    "            cropped_ims[int(x),int(y)] = image_master[xx:xx+crop_size,yy:yy+crop_size]\n",
    "    cropped_ims = cropped_ims.reshape((-1,crop_size,crop_size)).astype('float16')\n",
    "\n",
    "    return cropped_ims\n",
    "\n",
    "\n",
    "def resize_image(array, n, order = 3):\n",
    "    \"\"\"\n",
    "    Resize a numpy array to n x n using interpolation.\n",
    "\n",
    "    Parameters:\n",
    "    array (numpy.ndarray): The input array.\n",
    "    n (int): The size of the new square array.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The resized square array.\n",
    "    \"\"\"\n",
    "    # Get the current shape of the array\n",
    "    height, width = array.shape[-2:]\n",
    "\n",
    "    # Calculate zoom factors\n",
    "    zoom_factor = n / max(height, width)\n",
    "    array = array.astype(np.float32)\n",
    "\n",
    "    if len(array.shape) == 2:\n",
    "        return zoom(array, [zoom_factor, zoom_factor], order = order)\n",
    "    elif len(array.shape) == 3:\n",
    "        return zoom(array, [1,zoom_factor, zoom_factor], order = order)\n",
    "\n",
    "\n",
    "def shotgun_crop(image, crop_size=512, magnification_var = None, n_crops=10, seed=42, return_binary = False, roi = 'middle'):\n",
    "    \"\"\"\n",
    "    Randomly crops a specified number of sub-images from a given image with variable magnification, supporting images with any number of channels.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The input image as a NumPy array.\n",
    "    crop_size (int, optional): The default size for each square crop. Defaults to 512.\n",
    "    magnification_var (float, optional): The range of magnification variability as a fraction of the crop size. \n",
    "        If specified, each crop will be randomly sized within [crop_size * (1 - magnification_var), crop_size * (1 + magnification_var)]. Defaults to None.\n",
    "    n_crops (int, optional): The number of crops to generate. Defaults to 10.\n",
    "    seed (int, optional): Seed for the random number generator for reproducibility. Uses random package.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: An array containing the cropped (and potentially resized) images as NumPy arrays.\n",
    "\n",
    "    Important:\n",
    "    If using this funciton on an image and mask together, make sure to use the same seed for both.\n",
    "    \"\"\"\n",
    "\n",
    "    if return_binary == True:\n",
    "        order = 0\n",
    "    else:\n",
    "        order = 3\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    # Seed should be a very large integer for good results\n",
    "    crop_rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Get crop sizes for changing magnification later\n",
    "    if magnification_var is not None:\n",
    "        crop_sizes = crop_rng.integers(crop_size * ( 1 - magnification_var), crop_size * (1 + magnification_var), n_crops)\n",
    "        crop_sizes = crop_sizes.astype(int)\n",
    "    else:\n",
    "        crop_sizes = np.full(n_crops, crop_size)\n",
    "\n",
    "    # Randomly crop images (position and size)\n",
    "    h, w = image.shape[-2:]\n",
    "    crops = []\n",
    "    for size in crop_sizes:\n",
    "        if roi == 'middle':\n",
    "            edge_cutoff = crop_size//4\n",
    "            top = crop_rng.integers(edge_cutoff, h - size - edge_cutoff)\n",
    "            left = crop_rng.integers(edge_cutoff, w - size - edge_cutoff)\n",
    "        else:\n",
    "            top = crop_rng.integers(0, h - size)\n",
    "            left = crop_rng.integers(0, w - size)\n",
    "        if len(image.shape) > 2:\n",
    "            crop = image[:, top:top+size, left:left+size]\n",
    "            crop = resize_image(crop, crop_size, order)\n",
    "        else:\n",
    "            crop = image[top:top+size, left:left+size]\n",
    "            crop = resize_image(crop, crop_size, order)\n",
    "        crops.append(crop)\n",
    "\n",
    "    crops = np.array(crops)\n",
    "    batch_crops = np.stack(crops, axis=0)\n",
    "        \n",
    "    return batch_crops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88959ce",
   "metadata": {},
   "source": [
    "### 3. Introduce simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdbef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib ipympl\n",
    "\n",
    "from ase.io import read\n",
    "\n",
    "from abtem.atoms import orthogonalize_cell\n",
    "import pyTEMlib.probe_tools as pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b334b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download cif --> crystal structure of Tungsten Diselinide\n",
    "!wget https://raw.githubusercontent.com/AustinHouston/pystemsim/main/crystal_files/WS2.cif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e022e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scattering potential\n",
    "xtal = read('WS2.cif')\n",
    "xtal, transform = orthogonalize_cell(xtal, allow_transform=True, return_transform=True)\n",
    "xtal = xtal * (30, 20, 1)\n",
    "positions = xtal.get_positions()[:, :2]\n",
    "pixel_size = 0.106 # angstrom/pixel\n",
    "fov = 96 # angstroms\n",
    "frame = (0,fov,0,fov) # limits of the image in angstroms\n",
    "potential = create_pseudo_potential(xtal, pixel_size, sigma=1, bounds=frame, atom_frame=11)\n",
    "\n",
    "# Probe\n",
    "ab = pt.get_target_aberrations(\"Spectra300\", 60000)\n",
    "ab['acceleration_voltage'] = 60e3 # eV\n",
    "ab['FOV'] = fov /12 # Angstroms\n",
    "ab['convergence_angle'] = 30 # mrad\n",
    "ab['wavelength'] = pt.get_wavelength(ab['acceleration_voltage'])\n",
    "ab['C10'] = 1\n",
    "ab['C23a'] = 0\n",
    "ab['C23b'] = 0\n",
    "pt.print_aberrations(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ab here\n",
    "ab['C10'] = 0 # defocus\n",
    "ab['C12a'] = 0 # twofold astigmatism (a)\n",
    "ab['C12b'] = 0 # twofold astigmatism (b)\n",
    "probe = get_probe(ab, potential)\n",
    "image = convolve_kernel(potential, probe)\n",
    "noisy_image = lowfreq_noise(image, noise_level=0.5, freq_scale=.04)\n",
    "sim_im = poisson_noise(noisy_image, counts=1e7)\n",
    "\n",
    "view = sim_im.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a06ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_rms(im):\n",
    "    return np.std(im) / np.mean(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How contrast varies as we change defocus - c10\n",
    "param_range = 8\n",
    "params = np.linspace(-param_range, param_range, 21)\n",
    "\n",
    "rms_contrasts = []\n",
    "images = []\n",
    "for defocus in params:\n",
    "    ab['C10'] = defocus\n",
    "    probe = get_probe(ab, potential)\n",
    "    image = convolve_kernel(potential, probe)\n",
    "    noisy_image = lowfreq_noise(image, noise_level=0.5, freq_scale=.04)\n",
    "    sim_im = poisson_noise(noisy_image, counts=1e7)\n",
    "    rms_contrasts.append(contrast_rms(np.array(sim_im)))\n",
    "    images.append(sim_im)\n",
    "ab['C10'] = 0\n",
    "plt.figure()\n",
    "plt.plot(params, rms_contrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d59d568",
   "metadata": {},
   "source": [
    "### 4. Lets do Multiobjective GP on c1-a1 [ total 3 parametrs as a1 is a1x and a1y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd5bca",
   "metadata": {},
   "source": [
    "#### 4a. define reward functions, set parameter range and collect seed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1453cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SETUP STEM SIMULATOR ==========\n",
    "print(\"Setting up STEM simulator...\")\n",
    "xtal = read('WS2.cif')\n",
    "from abtem.atoms import orthogonalize_cell\n",
    "xtal, transform = orthogonalize_cell(xtal, allow_transform=True, return_transform=True)\n",
    "xtal = xtal * (30, 20, 1)\n",
    "\n",
    "pixel_size = 0.106\n",
    "fov = 96\n",
    "frame = (0, fov, 0, fov)\n",
    "potential = create_pseudo_potential(xtal, pixel_size, sigma=1, bounds=frame, atom_frame=11)\n",
    "\n",
    "# Setup probe aberrations\n",
    "ab = pt.get_target_aberrations(\"Spectra300\", 60000)\n",
    "ab['acceleration_voltage'] = 60e3\n",
    "ab['FOV'] = fov / 12\n",
    "ab['convergence_angle'] = 30\n",
    "ab['wavelength'] = pt.get_wavelength(ab['acceleration_voltage'])\n",
    "ab['C10'] = 1\n",
    "ab['C23a'] = 0\n",
    "ab['C23b'] = 0\n",
    "\n",
    "\n",
    "def contrast_rms(im, eps=1e-12):\n",
    "    m = np.mean(im)\n",
    "    return np.std(im) / (m + eps)\n",
    "\n",
    "def fft_snr_generic(im, kmin_frac=0.3, eps=1e-12):\n",
    "    h, w = im.shape\n",
    "    wy = np.hanning(h)[:, None]\n",
    "    wx = np.hanning(w)[None, :]\n",
    "    imw = im * wy * wx\n",
    "\n",
    "    F = np.fft.fftshift(np.fft.fft2(imw))\n",
    "    P = (np.abs(F)**2).astype(np.float64)\n",
    "    P /= (P.sum() + eps)  # dose/scale invariance\n",
    "\n",
    "    yy, xx = np.mgrid[0:h, 0:w]\n",
    "    cy, cx = h//2, w//2\n",
    "    rr = np.hypot(yy - cy, xx - cx)\n",
    "    rmax = rr.max()\n",
    "    high = rr >= (kmin_frac * rmax)\n",
    "    low  = (rr >= 0.05*rmax) & (rr < 0.15*rmax)  # background ring\n",
    "    return (P[high].mean()) / (P[low].mean() + eps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "def get_stem_image_contrast_and_fft(c10, c12a, c12b, plot_diagnostics=False):\n",
    "    ab['C10'] = c10\n",
    "    ab['C12a'] = c12a\n",
    "    ab['C12b'] = c12b\n",
    "    \n",
    "    probe = get_probe(ab, potential)\n",
    "    image = convolve_kernel(potential, probe)\n",
    "    noisy_image = lowfreq_noise(image, noise_level=0.5, freq_scale=0.04)\n",
    "    sim_im = poisson_noise(noisy_image, counts=1e7)\n",
    "    \n",
    "    contrast = contrast_rms(np.array(sim_im))\n",
    "    \n",
    "    sim_array = np.array(sim_im, dtype=float)\n",
    "    sim_array = (sim_array - sim_array.mean()) / sim_array.std()\n",
    "    \n",
    "    fft = np.fft.fft2(sim_array)\n",
    "    fft_shift = np.fft.fftshift(fft)\n",
    "    power = np.abs(fft_shift)**2\n",
    "    power_log = np.log1p(power)\n",
    "    \n",
    "    center = np.array(power.shape) // 2\n",
    "    y, x = np.ogrid[:power.shape[0], :power.shape[1]]\n",
    "    r = np.sqrt((x - center[1])**2 + (y - center[0])**2)\n",
    "    \n",
    "    power_log[center[0]-10:center[0]+10, center[1]-10:center[1]+10] = 0\n",
    "    \n",
    "    smoothed = ndimage.gaussian_filter(power_log, sigma=2)\n",
    "    \n",
    "    threshold = np.percentile(smoothed, 99.5)\n",
    "    peaks = smoothed > threshold\n",
    "    \n",
    "    labeled, num_peaks = ndimage.label(peaks)\n",
    "    \n",
    "    if num_peaks == 0:\n",
    "        fft_score = 0.0\n",
    "        max_radius = 0\n",
    "    else:\n",
    "        peak_distances = []\n",
    "        for i in range(1, num_peaks + 1):\n",
    "            peak_coords = np.where(labeled == i)\n",
    "            peak_y, peak_x = np.mean(peak_coords[0]), np.mean(peak_coords[1])\n",
    "            distance = np.sqrt((peak_x - center[1])**2 + (peak_y - center[0])**2)\n",
    "            peak_intensity = smoothed[labeled == i].max()\n",
    "            if distance > 15:\n",
    "                peak_distances.append((distance, peak_intensity))\n",
    "        \n",
    "        if len(peak_distances) > 0:\n",
    "            max_radius = max(d[0] for d in peak_distances)\n",
    "            fft_score = float(max_radius / min(center))\n",
    "        else:\n",
    "            max_radius = 0\n",
    "            fft_score = 0.0\n",
    "    \n",
    "    if plot_diagnostics:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        \n",
    "        axes[0,0].imshow(sim_im, cmap='gray')\n",
    "        axes[0,0].set_title('Original Image')\n",
    "        \n",
    "        axes[0,1].imshow(power_log, cmap='hot')\n",
    "        axes[0,1].set_title('FFT Power (log)')\n",
    "        \n",
    "        axes[0,2].imshow(smoothed, cmap='hot')\n",
    "        axes[0,2].set_title('Smoothed FFT')\n",
    "        \n",
    "        axes[1,0].imshow(peaks, cmap='gray')\n",
    "        axes[1,0].set_title(f'Detected Peaks ({num_peaks})')\n",
    "        \n",
    "        axes[1,1].imshow(power_log, cmap='hot')\n",
    "        if num_peaks > 0:\n",
    "            for i in range(1, num_peaks + 1):\n",
    "                peak_coords = np.where(labeled == i)\n",
    "                peak_y, peak_x = np.mean(peak_coords[0]), np.mean(peak_coords[1])\n",
    "                distance = np.sqrt((peak_x - center[1])**2 + (peak_y - center[0])**2)\n",
    "                if distance > 15:\n",
    "                    axes[1,1].plot(peak_x, peak_y, 'rx', markersize=10)\n",
    "                    if distance == max_radius:\n",
    "                        axes[1,1].plot(peak_x, peak_y, 'go', markersize=15, fillstyle='none', linewidth=2)\n",
    "        axes[1,1].plot(center[1], center[0], 'b+', markersize=20)\n",
    "        axes[1,1].set_title('Peaks Marked (Green=Farthest)')\n",
    "        \n",
    "        radial_profile = []\n",
    "        for rad in range(0, int(min(center))):\n",
    "            ring_mask = (r >= rad) & (r < rad+1)\n",
    "            if ring_mask.any():\n",
    "                radial_profile.append(smoothed[ring_mask].max())\n",
    "        axes[1,2].plot(radial_profile)\n",
    "        if max_radius > 0:\n",
    "            axes[1,2].axvline(max_radius, color='g', linestyle='--', linewidth=2, label=f'Max peak: {max_radius:.1f}px')\n",
    "        axes[1,2].axhline(threshold, color='r', linestyle='--', label='threshold')\n",
    "        axes[1,2].set_xlabel('Radius (px)')\n",
    "        axes[1,2].set_ylabel('Max Power')\n",
    "        axes[1,2].legend()\n",
    "        axes[1,2].set_title('Radial Power Profile')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'FFT Score: {fft_score:.3f} (max_r={max_radius:.1f}px)', y=1.00, fontsize=14)\n",
    "        plt.show()\n",
    "    \n",
    "    return contrast, fft_score, sim_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ea9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter ranges based on your exploration\n",
    "param_ranges = {\n",
    "    'C10': (-8, 8),    # defocus\n",
    "    'C12a': (-10, 10), # twofold astigmatism (a)\n",
    "    'C12b': (-10, 10)  # twofold astigmatism (b)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full grid (coarser for computational efficiency)\n",
    "n_grid = 7  # 7^3 = 343 points\n",
    "c10_grid = np.linspace(*param_ranges['C10'], n_grid)\n",
    "c12a_grid = np.linspace(*param_ranges['C12a'], n_grid)\n",
    "c12b_grid = np.linspace(*param_ranges['C12b'], n_grid)\n",
    "C10, C12A, C12B = np.meshgrid(c10_grid, c12a_grid, c12b_grid, indexing='ij')\n",
    "full_grid = np.stack([C10.flatten(), C12A.flatten(), C12B.flatten()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample seed points\n",
    "n_seed = 4\n",
    "seed_indices = np.random.choice(len(full_grid), n_seed, replace=False)\n",
    "seed_points = full_grid[seed_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========== QUERY SEED POINTS ==========\n",
    "# print(f\"\\nQuerying {n_seed} seed points...\")\n",
    "# seed_scores = []\n",
    "# seed_images = []\n",
    "\n",
    "# for i, (c23a, c23b, c21a, c21b) in enumerate(seed_points):\n",
    "#     contrast, sim_im = get_stem_image_contrast(c23a, c23b, c21a, c21b)\n",
    "#     seed_scores.append(contrast)\n",
    "#     seed_images.append(sim_im)\n",
    "#     print(f\"Seed {i+1}/{n_seed}, C23a={c23a:.2f}, C23b={c23b:.2f},  C21a={c21a:.2f}, C21b={c21b:.2f}, contrast={contrast:.4f}\")\n",
    "\n",
    "# seed_scores = np.array(seed_scores)\n",
    "\n",
    "# ========== QUERY SEED POINTS ==========\n",
    "print(f\"\\nQuerying {n_seed} seed points...\")\n",
    "seed_scores = []\n",
    "seed_images = []\n",
    "\n",
    "for i, (c10, c12a, c12b) in enumerate(seed_points):\n",
    "    contrast, fft_score, sim_im = get_stem_image_contrast_and_fft(c10, c12a, c12b, plot_diagnostics=True)\n",
    "    rewards = np.array((contrast, fft_score))\n",
    "    seed_scores.append(rewards)\n",
    "    seed_images.append(sim_im)\n",
    "    # print(f\"Seed {i+1}/{n_seed}, C23a={c23a:.2f}, C23b={c23b:.2f},  C21a={c21a:.2f}, C21b={c21b:.2f}, contrast={contrast:.4f}\")\n",
    "\n",
    "seed_scores = np.array(seed_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef319f",
   "metadata": {},
   "source": [
    "#### 4b. MOBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1907d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from botorch.acquisition.multi_objective import qLogExpectedHypervolumeImprovement \n",
    "from botorch.utils.multi_objective.box_decompositions import NondominatedPartitioning\n",
    "from botorch.utils.multi_objective import is_non_dominated\n",
    "\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cdf82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== INITIAL SEED POINTS (from previous code) ==========\n",
    "print(f\"Starting with {n_seed} seed points...\")\n",
    "print(f\"Best initial contrast: {seed_scores.max():.4f}\")\n",
    "\n",
    "# Convert to tensors\n",
    "train_X = torch.tensor(seed_points, dtype=torch.float64)\n",
    "train_Y = torch.tensor(seed_scores, dtype=torch.float64)\n",
    "\n",
    "# Define bounds for optimization\n",
    "bounds = torch.tensor([\n",
    "    [param_ranges['C10'][0], param_ranges['C12a'][0], param_ranges['C12b'][0]],  # lower bounds\n",
    "    [param_ranges['C10'][1], param_ranges['C12a'][1], param_ranges['C12b'][1]]   # upper bounds\n",
    "], dtype=torch.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae763ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ---- device & dtype ----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float64\n",
    "\n",
    "torch.set_default_dtype(dtype)\n",
    "\n",
    "# move inputs/bounds to device+dtype\n",
    "train_X = train_X.to(device=device, dtype=dtype)\n",
    "train_Y = train_Y.to(device=device, dtype=dtype)\n",
    "bounds  = bounds.to(device=device, dtype=dtype)\n",
    "\n",
    "n_bo_steps = 50\n",
    "all_X = train_X.clone()\n",
    "all_Y = train_Y.clone()\n",
    "all_images = seed_images.copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Multi-Objective Bayesian Optimization with EHVI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ref_point = train_Y.min(dim=0).values - 0.1 * train_Y.std(dim=0)\n",
    "print(f\"Reference point: {ref_point.detach().cpu().numpy()}\")\n",
    "\n",
    "for step in range(n_bo_steps):\n",
    "    print(f\"\\n--- BO Step {step + 1}/{n_bo_steps} ---\")\n",
    "    \n",
    "    # Train GP (model follows tensor's device/dtype)\n",
    "    print(\"Training Multi-Output GP...\")\n",
    "    gp_model = SingleTaskGP(\n",
    "        all_X, all_Y,\n",
    "        input_transform=Normalize(d=all_X.shape[-1]).to(device=device, dtype=dtype),\n",
    "        outcome_transform=Standardize(m=all_Y.shape[-1]).to(device=device, dtype=dtype),\n",
    "    ).to(device=device, dtype=dtype)\n",
    "    \n",
    "    gp_model.likelihood.noise_covar.initialize(noise=0.01)\n",
    "    mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model).to(device=device, dtype=dtype)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    \n",
    "    # EHVI acquisition\n",
    "    print(\"Computing Pareto frontier...\")\n",
    "    pareto_mask = is_non_dominated(all_Y)\n",
    "    pareto_Y = all_Y[pareto_mask]\n",
    "    print(f\"Pareto frontier size: {pareto_Y.shape[0]}\")\n",
    "    \n",
    "    partitioning = NondominatedPartitioning(ref_point=ref_point, Y=pareto_Y)\n",
    "    EHVI = qLogExpectedHypervolumeImprovement(\n",
    "        model=gp_model,\n",
    "        ref_point=ref_point.tolist(),\n",
    "        partitioning=partitioning,\n",
    "    )\n",
    "    \n",
    "    # Optimize\n",
    "    print(\"Optimizing acquisition function...\")\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        acq_function=EHVI,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=10,\n",
    "        raw_samples=100,\n",
    "    )\n",
    "    \n",
    "    next_X = candidate.detach()\n",
    "    next_params = next_X.squeeze().detach().cpu().numpy()\n",
    "    print(f\"EHVI value: {acq_value:.6f}\")\n",
    "    \n",
    "    # Query simulator (returns CPU values)\n",
    "    print(\"Querying STEM simulator...\")\n",
    "    objective1, objective2, next_image = get_stem_image_contrast_and_fft(\n",
    "        next_params[0], next_params[1], next_params[2], plot_diagnostics=True\n",
    "    )\n",
    "    next_Y = torch.tensor([[objective1, objective2]], dtype=dtype, device=device)\n",
    "    \n",
    "    print(f\"Observed objectives: [{objective1:.4f}, {objective2:.4f}]\")\n",
    "    \n",
    "    # Update tensors on-device\n",
    "    all_X = torch.cat([all_X, next_X], dim=0)\n",
    "    all_Y = torch.cat([all_Y, next_Y], dim=0)\n",
    "    all_images.append(next_image)\n",
    "    \n",
    "    new_pareto_mask = is_non_dominated(all_Y)\n",
    "    if new_pareto_mask[-1]:\n",
    "        print(\"✓ NEW PARETO POINT!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e968563",
   "metadata": {},
   "source": [
    "#### 4c. Lets look at Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FIND EXTREME AND MID PARETO POINTS ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Pareto Frontier Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_pareto_mask = is_non_dominated(all_Y)\n",
    "final_pareto_X = all_X[final_pareto_mask]\n",
    "final_pareto_Y = all_Y[final_pareto_mask]\n",
    "pareto_indices = torch.where(final_pareto_mask)[0].cpu().numpy()\n",
    "\n",
    "print(f\"Number of Pareto optimal points: {final_pareto_Y.shape[0]}\")\n",
    "\n",
    "# Find extreme points\n",
    "extreme_indices = []\n",
    "\n",
    "# Extreme for Objective 1\n",
    "max_obj1_idx = torch.argmax(final_pareto_Y[:, 0]).item()\n",
    "min_obj1_idx = torch.argmin(final_pareto_Y[:, 0]).item()\n",
    "\n",
    "# Extreme for Objective 2\n",
    "max_obj2_idx = torch.argmax(final_pareto_Y[:, 1]).item()\n",
    "min_obj2_idx = torch.argmin(final_pareto_Y[:, 1]).item()\n",
    "\n",
    "extreme_indices.extend([max_obj1_idx, min_obj1_idx, max_obj2_idx, min_obj2_idx])\n",
    "extreme_indices = list(set(extreme_indices))  # Remove duplicates\n",
    "\n",
    "# Find middle point (balanced trade-off)\n",
    "# Normalize objectives to [0,1] then find point closest to (0.5, 0.5)\n",
    "normalized_pareto_Y = (final_pareto_Y - final_pareto_Y.min(dim=0).values) / (final_pareto_Y.max(dim=0).values - final_pareto_Y.min(dim=0).values + 1e-8)\n",
    "distances_to_center = torch.norm(normalized_pareto_Y - 0.5, dim=1)\n",
    "mid_idx = torch.argmin(distances_to_center).item()\n",
    "\n",
    "# Combine: extremes + mid\n",
    "selected_indices = sorted(list(set(extreme_indices + [mid_idx])))\n",
    "\n",
    "print(f\"\\nSelected Pareto points for visualization: {len(selected_indices)}\")\n",
    "for idx in selected_indices:\n",
    "    pareto_idx = pareto_indices[idx]\n",
    "    params = all_X[pareto_idx].cpu().numpy()\n",
    "    obj1, obj2 = all_Y[pareto_idx, 0].item(), all_Y[pareto_idx, 1].item()\n",
    "    \n",
    "    label = \"\"\n",
    "    if idx == max_obj1_idx:\n",
    "        label += \"[MAX Obj1] \"\n",
    "    if idx == min_obj1_idx:\n",
    "        label += \"[MIN Obj1] \"\n",
    "    if idx == max_obj2_idx:\n",
    "        label += \"[MAX Obj2] \"\n",
    "    if idx == min_obj2_idx:\n",
    "        label += \"[MIN Obj2] \"\n",
    "    if idx == mid_idx:\n",
    "        label += \"[MID/Balanced] \"\n",
    "    \n",
    "    print(f\"  {label}\")\n",
    "    print(f\"    Obj1={obj1:.4f}, Obj2={obj2:.4f}\")\n",
    "    print(f\"    C10={params[0]:.2f}, C12a={params[1]:.2f}, C12b={params[2]:.2f}\")\n",
    "\n",
    "# ========== VISUALIZE ONLY EXTREME + MID PARETO IMAGES ==========\n",
    "n_selected = len(selected_indices)\n",
    "n_cols = min(3, n_selected)\n",
    "n_rows = int(np.ceil(n_selected / n_cols))\n",
    "\n",
    "fig = plt.figure(figsize=(7*n_cols, 7*n_rows))\n",
    "\n",
    "for plot_idx, pareto_idx_in_frontier in enumerate(selected_indices):\n",
    "    ax = fig.add_subplot(n_rows, n_cols, plot_idx + 1)\n",
    "    \n",
    "    pareto_idx = pareto_indices[pareto_idx_in_frontier]\n",
    "    img = all_images[pareto_idx]\n",
    "    params = all_X[pareto_idx].cpu().numpy()\n",
    "    obj1, obj2 = all_Y[pareto_idx, 0].item(), all_Y[pareto_idx, 1].item()\n",
    "    \n",
    "    # Determine label\n",
    "    label = \"\"\n",
    "    if pareto_idx_in_frontier == max_obj1_idx:\n",
    "        label = \"MAX Obj1\"\n",
    "        color = 'red'\n",
    "    elif pareto_idx_in_frontier == min_obj1_idx:\n",
    "        label = \"MIN Obj1\"\n",
    "        color = 'blue'\n",
    "    elif pareto_idx_in_frontier == max_obj2_idx:\n",
    "        label = \"MAX Obj2\"\n",
    "        color = 'green'\n",
    "    elif pareto_idx_in_frontier == min_obj2_idx:\n",
    "        label = \"MIN Obj2\"\n",
    "        color = 'orange'\n",
    "    elif pareto_idx_in_frontier == mid_idx:\n",
    "        label = \"BALANCED (Mid)\"\n",
    "        color = 'purple'\n",
    "    else:\n",
    "        label = \"Extreme\"\n",
    "        color = 'black'\n",
    "    \n",
    "\n",
    "    ax.imshow(np.array(img), cmap='gray')\n",
    "    ax.set_title(\n",
    "        f'{label}\\n'\n",
    "        f'Obj1={obj1:.4f}, Obj2={obj2:.4f}\\n'\n",
    "        f'C10={params[0]:.1f}, C12a={params[1]:.1f}\\n'\n",
    "        f'C12b={params[2]:.1f}\\n',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "        color=color\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pareto_extreme_mid_images.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ========== COMBINED RESULTS PLOT ==========\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# 1. Objective space\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "ax1.scatter(all_Y[:, 0].cpu().numpy(), all_Y[:, 1].cpu().numpy(), \n",
    "           c='lightblue', s=150, alpha=0.6, edgecolors='gray',\n",
    "           label='All evaluations')\n",
    "ax1.scatter(final_pareto_Y[:, 0].cpu().numpy(), final_pareto_Y[:, 1].cpu().numpy(), \n",
    "           c='lightcoral', s=200, alpha=0.5, edgecolors='black', \n",
    "           linewidths=1, label='Pareto frontier')\n",
    "\n",
    "# Highlight extreme and mid points\n",
    "colors = []\n",
    "labels_legend = []\n",
    "for idx in selected_indices:\n",
    "    if idx == max_obj1_idx:\n",
    "        colors.append('red')\n",
    "        if 'MAX Obj1' not in labels_legend:\n",
    "            labels_legend.append('MAX Obj1')\n",
    "    elif idx == max_obj2_idx:\n",
    "        colors.append('green')\n",
    "        if 'MAX Obj2' not in labels_legend:\n",
    "            labels_legend.append('MAX Obj2')\n",
    "    elif idx == mid_idx:\n",
    "        colors.append('purple')\n",
    "        if 'Balanced' not in labels_legend:\n",
    "            labels_legend.append('Balanced')\n",
    "    else:\n",
    "        colors.append('orange')\n",
    "\n",
    "for idx, color in zip(selected_indices, colors):\n",
    "    ax1.scatter(final_pareto_Y[idx, 0].cpu().numpy(), final_pareto_Y[idx, 1].cpu().numpy(),\n",
    "               c=color, s=400, marker='*', edgecolors='black', linewidths=2, zorder=10)\n",
    "\n",
    "ax1.set_xlabel('Objective 1 (Contrast)', fontsize=12)\n",
    "ax1.set_ylabel('Objective 2 (Other Metric)', fontsize=12)\n",
    "ax1.set_title('Pareto Frontier (★ = Extreme/Mid points)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. BO progress\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "iterations = range(len(all_Y))\n",
    "ax2.plot(iterations, all_Y[:, 0].cpu().numpy(), 'o-', label='Objective 1', \n",
    "        alpha=0.7, linewidth=2, markersize=8)\n",
    "ax2.plot(iterations, all_Y[:, 1].cpu().numpy(), 's-', label='Objective 2', \n",
    "        alpha=0.7, linewidth=2, markersize=8)\n",
    "ax2.axvline(len(train_Y)-1, color='red', linestyle='--', \n",
    "          label='BO start', linewidth=2)\n",
    "ax2.set_xlabel('Iteration', fontsize=12)\n",
    "ax2.set_ylabel('Objective Value', fontsize=12)\n",
    "ax2.set_title('BO Progress', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Hypervolume\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "\n",
    "hv_computer = Hypervolume(ref_point=ref_point)\n",
    "hypervolumes = []\n",
    "for i in range(len(train_Y), len(all_Y) + 1):\n",
    "    current_Y = all_Y[:i]\n",
    "    pareto_mask_i = is_non_dominated(current_Y)\n",
    "    pareto_Y_i = current_Y[pareto_mask_i]\n",
    "    hv = hv_computer.compute(pareto_Y_i)\n",
    "    hypervolumes.append(hv)\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "ax3.plot(range(len(train_Y), len(all_Y) + 1), hypervolumes, 'o-', \n",
    "        linewidth=2, markersize=8, color='purple')\n",
    "ax3.set_xlabel('Iteration', fontsize=12)\n",
    "ax3.set_ylabel('Hypervolume', fontsize=12)\n",
    "ax3.set_title('Hypervolume Improvement', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('multi_objective_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(f\"Total evaluations: {len(all_Y)}\")\n",
    "print(f\"Pareto frontier size: {len(pareto_indices)}\")\n",
    "print(f\"Extreme + Mid points shown: {len(selected_indices)}\")\n",
    "print(f\"Final hypervolume: {hypervolumes[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263ba80",
   "metadata": {},
   "source": [
    "### 5. Lets do Multiobjective GP on b2-a2 [ total 4 parametrs as b2 is b2x and b2y and a2 is aa2x and a2y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a421f9",
   "metadata": {},
   "source": [
    "#### 5a. define reward functions, set parameter range and collect seed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00bc435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SETUP STEM SIMULATOR ==========\n",
    "print(\"Setting up STEM simulator...\")\n",
    "xtal = read('WS2.cif')\n",
    "from abtem.atoms import orthogonalize_cell\n",
    "xtal, transform = orthogonalize_cell(xtal, allow_transform=True, return_transform=True)\n",
    "xtal = xtal * (30, 20, 1)\n",
    "\n",
    "pixel_size = 0.106\n",
    "fov = 96\n",
    "frame = (0, fov, 0, fov)\n",
    "potential = create_pseudo_potential(xtal, pixel_size, sigma=1, bounds=frame, atom_frame=11)\n",
    "\n",
    "# Setup probe aberrations\n",
    "ab = pt.get_target_aberrations(\"Spectra300\", 60000)\n",
    "ab['acceleration_voltage'] = 60e3\n",
    "ab['FOV'] = fov / 12\n",
    "ab['convergence_angle'] = 30\n",
    "ab['wavelength'] = pt.get_wavelength(ab['acceleration_voltage'])\n",
    "ab['C10'] = 1\n",
    "ab['C23a'] = 0\n",
    "ab['C23b'] = 0\n",
    "\n",
    "\n",
    "def contrast_rms(im, eps=1e-12):\n",
    "    m = np.mean(im)\n",
    "    return np.std(im) / (m + eps)\n",
    "\n",
    "def fft_snr_generic(im, kmin_frac=0.3, eps=1e-12):\n",
    "    h, w = im.shape\n",
    "    wy = np.hanning(h)[:, None]\n",
    "    wx = np.hanning(w)[None, :]\n",
    "    imw = im * wy * wx\n",
    "\n",
    "    F = np.fft.fftshift(np.fft.fft2(imw))\n",
    "    P = (np.abs(F)**2).astype(np.float64)\n",
    "    P /= (P.sum() + eps)  # dose/scale invariance\n",
    "\n",
    "    yy, xx = np.mgrid[0:h, 0:w]\n",
    "    cy, cx = h//2, w//2\n",
    "    rr = np.hypot(yy - cy, xx - cx)\n",
    "    rmax = rr.max()\n",
    "    high = rr >= (kmin_frac * rmax)\n",
    "    low  = (rr >= 0.05*rmax) & (rr < 0.15*rmax)  # background ring\n",
    "    return (P[high].mean()) / (P[low].mean() + eps)\n",
    "\n",
    "\n",
    "def get_stem_image_contrast(c23a, c23b, c21a, c21b):\n",
    "    \"\"\"Generate STEM image and return contrast for given aberrations\"\"\"\n",
    "    # ab['C10'] = c10\n",
    "    ab['C23a'] = c23a\n",
    "    ab['C23b'] = c23b\n",
    "    ab['C21a'] = c21a\n",
    "    ab['C21b'] = c21b\n",
    "\n",
    "    \n",
    "    probe = dg.get_probe(ab, potential)\n",
    "    image = dg.convolve_kernel(potential, probe)\n",
    "    noisy_image = dg.lowfreq_noise(image, noise_level=0.5, freq_scale=0.04)\n",
    "    sim_im = dg.poisson_noise(noisy_image, counts=1e7)\n",
    "    \n",
    "    contrast = contrast_rms(np.array(sim_im))\n",
    "    return contrast, sim_im\n",
    "\n",
    "def get_stem_image_contrast_and_fft(c23a, c23b, c21a, c21b):\n",
    "    \"\"\"Generate STEM image and return contrast for given aberrations\"\"\"\n",
    "    # ab['C10'] = c10\n",
    "    ab['C23a'] = c23a\n",
    "    ab['C23b'] = c23b\n",
    "    ab['C21a'] = c21a\n",
    "    ab['C21b'] = c21b\n",
    "\n",
    "    \n",
    "    probe = get_probe(ab, potential)\n",
    "    image = convolve_kernel(potential, probe)\n",
    "    noisy_image = lowfreq_noise(image, noise_level=0.5, freq_scale=0.04)\n",
    "    sim_im = poisson_noise(noisy_image, counts=1e7)\n",
    "    \n",
    "    contrast = contrast_rms(np.array(sim_im))\n",
    "    \n",
    "    fft_score = fft_snr_generic(np.array(sim_im))\n",
    "    return contrast, fft_score, sim_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import botorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter ranges based on your exploration\n",
    "param_ranges = {\n",
    "    # 'C10': (-8, 8),    # defocus\n",
    "    'C23a': (-200, 200), # twofold astigmatism (a)\n",
    "    'C23b': (-200, 200), # twofold astigmatism (a)\n",
    "\n",
    "    'C21a': (-500, 500),  # twofold astigmatism (b)\n",
    "    'C21b': (-500, 500)  # twofold astigmatism (b)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da11cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full grid (coarser for computational efficiency)\n",
    "n_grid = 20  # 7^3 = 343 points\n",
    "# c10_grid = np.linspace(*param_ranges['C10'], n_grid)\n",
    "c23a_grid = np.linspace(*param_ranges['C23a'], n_grid)\n",
    "c23b_grid = np.linspace(*param_ranges['C23b'], n_grid)\n",
    "\n",
    "c21a_grid = np.linspace(*param_ranges['C21a'], n_grid)\n",
    "c21b_grid = np.linspace(*param_ranges['C21b'], n_grid)\n",
    "\n",
    "C23A, C23B, C21A, C21B = np.meshgrid( c23a_grid, c23b_grid, c21a_grid, c21b_grid, indexing='ij')\n",
    "full_grid = np.stack([C23A.flatten(), C23B.flatten(),  C21A.flatten(), C21B.flatten()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfd9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample seed points\n",
    "n_seed = 3\n",
    "seed_indices = np.random.choice(len(full_grid), n_seed, replace=False)\n",
    "seed_points = full_grid[seed_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========== QUERY SEED POINTS ==========\n",
    "# print(f\"\\nQuerying {n_seed} seed points...\")\n",
    "# seed_scores = []\n",
    "# seed_images = []\n",
    "\n",
    "# for i, (c23a, c23b, c21a, c21b) in enumerate(seed_points):\n",
    "#     contrast, sim_im = get_stem_image_contrast(c23a, c23b, c21a, c21b)\n",
    "#     seed_scores.append(contrast)\n",
    "#     seed_images.append(sim_im)\n",
    "#     print(f\"Seed {i+1}/{n_seed}, C23a={c23a:.2f}, C23b={c23b:.2f},  C21a={c21a:.2f}, C21b={c21b:.2f}, contrast={contrast:.4f}\")\n",
    "\n",
    "# seed_scores = np.array(seed_scores)\n",
    "\n",
    "\n",
    "# ========== QUERY SEED POINTS ==========\n",
    "print(f\"\\nQuerying {n_seed} seed points...\")\n",
    "seed_scores = []\n",
    "seed_images = []\n",
    "\n",
    "for i, (c23a, c23b, c21a, c21b) in enumerate(seed_points):\n",
    "    contrast, fft_score, sim_im = get_stem_image_contrast_and_fft(c23a, c23b, c21a, c21b)\n",
    "    rewards = np.array((contrast, fft_score))\n",
    "    seed_scores.append(rewards)\n",
    "    seed_images.append(sim_im)\n",
    "    # print(f\"Seed {i+1}/{n_seed}, C23a={c23a:.2f}, C23b={c23b:.2f},  C21a={c21a:.2f}, C21b={c21b:.2f}, contrast={contrast:.4f}\")\n",
    "\n",
    "seed_scores = np.array(seed_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456f4e3",
   "metadata": {},
   "source": [
    "#### 5b. MOBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dbea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from botorch.acquisition.multi_objective import qLogExpectedHypervolumeImprovement \n",
    "from botorch.utils.multi_objective.box_decompositions import NondominatedPartitioning\n",
    "from botorch.utils.multi_objective import is_non_dominated\n",
    "\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== INITIAL SEED POINTS (from previous code) ==========\n",
    "print(f\"Starting with {n_seed} seed points...\")\n",
    "print(f\"Best initial contrast: {seed_scores.max():.4f}\")\n",
    "\n",
    "# Convert to tensors\n",
    "train_X = torch.tensor(seed_points, dtype=torch.float64)\n",
    "train_Y = torch.tensor(seed_scores, dtype=torch.float64)\n",
    "\n",
    "# Define bounds for optimization\n",
    "bounds = torch.tensor([\n",
    "    [param_ranges['C23a'][0], param_ranges['C23b'][0], param_ranges['C21a'][0], param_ranges['C21b'][0]],  # lower bounds\n",
    "    [param_ranges['C23a'][1], param_ranges['C23b'][1], param_ranges['C21a'][1], param_ranges['C21b'][1]]   # upper bounds\n",
    "], dtype=torch.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71408ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed objectives: [0.4826, 0.0175]\n",
      "\n",
      "--- BO Step 50/50 ---\n",
      "Training Multi-Output GP...\n",
      "Computing Pareto frontier...\n",
      "Pareto frontier size: 39\n",
      "Optimizing acquisition function...\n",
      "EHVI value: -10.172721\n",
      "Querying STEM simulator...\n",
      "0.03\n",
      "Observed objectives: [0.5048, 0.0156]\n",
      "✓ NEW PARETO POINT!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ---- device & dtype ----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float64\n",
    "torch.set_default_dtype(dtype)\n",
    "\n",
    "# move inputs/bounds to device+dtype\n",
    "train_X = train_X.to(device=device, dtype=dtype)\n",
    "train_Y = train_Y.to(device=device, dtype=dtype)\n",
    "bounds  = bounds.to(device=device, dtype=dtype)\n",
    "\n",
    "n_bo_steps = 50\n",
    "all_X = train_X.clone()\n",
    "all_Y = train_Y.clone()\n",
    "all_images = seed_images.copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Multi-Objective Bayesian Optimization with EHVI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ref_point = train_Y.min(dim=0).values - 0.1 * train_Y.std(dim=0)\n",
    "print(f\"Reference point: {ref_point.detach().cpu().numpy()}\")\n",
    "\n",
    "for step in range(n_bo_steps):\n",
    "    print(f\"\\n--- BO Step {step + 1}/{n_bo_steps} ---\")\n",
    "    \n",
    "    # Train GP (ensure model, transforms, mll on same device/dtype)\n",
    "    print(\"Training Multi-Output GP...\")\n",
    "    gp_model = SingleTaskGP(\n",
    "        all_X, all_Y,\n",
    "        input_transform=Normalize(d=all_X.shape[-1]).to(device=device, dtype=dtype),\n",
    "        outcome_transform=Standardize(m=all_Y.shape[-1]).to(device=device, dtype=dtype),\n",
    "    ).to(device=device, dtype=dtype)\n",
    "    \n",
    "    gp_model.likelihood.noise_covar.initialize(noise=0.01)\n",
    "    mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model).to(device=device, dtype=dtype)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    \n",
    "    # EHVI acquisition\n",
    "    print(\"Computing Pareto frontier...\")\n",
    "    pareto_mask = is_non_dominated(all_Y)\n",
    "    pareto_Y = all_Y[pareto_mask]\n",
    "    print(f\"Pareto frontier size: {pareto_Y.shape[0]}\")\n",
    "    \n",
    "    partitioning = NondominatedPartitioning(ref_point=ref_point, Y=pareto_Y)\n",
    "    EHVI = qLogExpectedHypervolumeImprovement(\n",
    "        model=gp_model,\n",
    "        ref_point=ref_point.tolist(),  # list is fine for EHVI\n",
    "        partitioning=partitioning,\n",
    "    )\n",
    "    \n",
    "    # Optimize (bounds already on correct device/dtype)\n",
    "    print(\"Optimizing acquisition function...\")\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        acq_function=EHVI,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=10,\n",
    "        raw_samples=100,\n",
    "    )\n",
    "    \n",
    "    next_X = candidate.detach()  # stays on device\n",
    "    next_params = next_X.squeeze().detach().cpu().numpy()  # CPU for simulator\n",
    "    print(f\"EHVI value: {acq_value:.6f}\")\n",
    "    \n",
    "    # Query\n",
    "    print(\"Querying STEM simulator...\")\n",
    "    objective1, objective2, next_image = get_stem_image_contrast_and_fft(\n",
    "        next_params[0], next_params[1], next_params[2], next_params[3]\n",
    "    )\n",
    "    next_Y = torch.tensor([[objective1, objective2]], dtype=dtype, device=device)\n",
    "    \n",
    "    print(f\"Observed objectives: [{objective1:.4f}, {objective2:.4f}]\")\n",
    "    \n",
    "    # Update (tensors already on device)\n",
    "    all_X = torch.cat([all_X, next_X], dim=0)\n",
    "    all_Y = torch.cat([all_Y, next_Y], dim=0)\n",
    "    all_images.append(next_image)\n",
    "    \n",
    "    new_pareto_mask = is_non_dominated(all_Y)\n",
    "    if new_pareto_mask[-1]:\n",
    "        print(\"✓ NEW PARETO POINT!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74e4052",
   "metadata": {},
   "source": [
    "#### 5c. Lets look at Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FIND EXTREME AND MID PARETO POINTS ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Pareto Frontier Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_pareto_mask = is_non_dominated(all_Y)\n",
    "final_pareto_X = all_X[final_pareto_mask]\n",
    "final_pareto_Y = all_Y[final_pareto_mask]\n",
    "pareto_indices = torch.where(final_pareto_mask)[0].numpy()\n",
    "\n",
    "print(f\"Number of Pareto optimal points: {final_pareto_Y.shape[0]}\")\n",
    "\n",
    "# Find extreme points\n",
    "extreme_indices = []\n",
    "\n",
    "# Extreme for Objective 1\n",
    "max_obj1_idx = torch.argmax(final_pareto_Y[:, 0]).item()\n",
    "min_obj1_idx = torch.argmin(final_pareto_Y[:, 0]).item()\n",
    "\n",
    "# Extreme for Objective 2\n",
    "max_obj2_idx = torch.argmax(final_pareto_Y[:, 1]).item()\n",
    "min_obj2_idx = torch.argmin(final_pareto_Y[:, 1]).item()\n",
    "\n",
    "extreme_indices.extend([max_obj1_idx, min_obj1_idx, max_obj2_idx, min_obj2_idx])\n",
    "extreme_indices = list(set(extreme_indices))  # Remove duplicates\n",
    "\n",
    "# Find middle point (balanced trade-off)\n",
    "# Normalize objectives to [0,1] then find point closest to (0.5, 0.5)\n",
    "normalized_pareto_Y = (final_pareto_Y - final_pareto_Y.min(dim=0).values) / (final_pareto_Y.max(dim=0).values - final_pareto_Y.min(dim=0).values + 1e-8)\n",
    "distances_to_center = torch.norm(normalized_pareto_Y - 0.5, dim=1)\n",
    "mid_idx = torch.argmin(distances_to_center).item()\n",
    "\n",
    "# Combine: extremes + mid\n",
    "selected_indices = sorted(list(set(extreme_indices + [mid_idx])))\n",
    "\n",
    "print(f\"\\nSelected Pareto points for visualization: {len(selected_indices)}\")\n",
    "for idx in selected_indices:\n",
    "    pareto_idx = pareto_indices[idx]\n",
    "    params = all_X[pareto_idx].numpy()\n",
    "    obj1, obj2 = all_Y[pareto_idx, 0].item(), all_Y[pareto_idx, 1].item()\n",
    "    \n",
    "    label = \"\"\n",
    "    if idx == max_obj1_idx:\n",
    "        label += \"[MAX Obj1] \"\n",
    "    if idx == min_obj1_idx:\n",
    "        label += \"[MIN Obj1] \"\n",
    "    if idx == max_obj2_idx:\n",
    "        label += \"[MAX Obj2] \"\n",
    "    if idx == min_obj2_idx:\n",
    "        label += \"[MIN Obj2] \"\n",
    "    if idx == mid_idx:\n",
    "        label += \"[MID/Balanced] \"\n",
    "    \n",
    "    print(f\"  {label}\")\n",
    "    print(f\"    Obj1={obj1:.4f}, Obj2={obj2:.4f}\")\n",
    "    print(f\"    C23a={params[0]:.2f}, C23b={params[1]:.2f}, C21a={params[2]:.2f}, C21b={params[3]:.2f}\")\n",
    "\n",
    "# ========== VISUALIZE ONLY EXTREME + MID PARETO IMAGES ==========\n",
    "n_selected = len(selected_indices)\n",
    "n_cols = min(3, n_selected)\n",
    "n_rows = int(np.ceil(n_selected / n_cols))\n",
    "\n",
    "fig = plt.figure(figsize=(7*n_cols, 7*n_rows))\n",
    "\n",
    "for plot_idx, pareto_idx_in_frontier in enumerate(selected_indices):\n",
    "    ax = fig.add_subplot(n_rows, n_cols, plot_idx + 1)\n",
    "    \n",
    "    pareto_idx = pareto_indices[pareto_idx_in_frontier]\n",
    "    img = all_images[pareto_idx]\n",
    "    params = all_X[pareto_idx].numpy()\n",
    "    obj1, obj2 = all_Y[pareto_idx, 0].item(), all_Y[pareto_idx, 1].item()\n",
    "    \n",
    "    # Determine label\n",
    "    label = \"\"\n",
    "    if pareto_idx_in_frontier == max_obj1_idx:\n",
    "        label = \"MAX Obj1\"\n",
    "        color = 'red'\n",
    "    elif pareto_idx_in_frontier == min_obj1_idx:\n",
    "        label = \"MIN Obj1\"\n",
    "        color = 'blue'\n",
    "    elif pareto_idx_in_frontier == max_obj2_idx:\n",
    "        label = \"MAX Obj2\"\n",
    "        color = 'green'\n",
    "    elif pareto_idx_in_frontier == min_obj2_idx:\n",
    "        label = \"MIN Obj2\"\n",
    "        color = 'orange'\n",
    "    elif pareto_idx_in_frontier == mid_idx:\n",
    "        label = \"BALANCED (Mid)\"\n",
    "        color = 'purple'\n",
    "    else:\n",
    "        label = \"Extreme\"\n",
    "        color = 'black'\n",
    "    \n",
    "    ax.imshow(np.array(img), cmap='gray')\n",
    "    ax.set_title(\n",
    "        f'{label}\\n'\n",
    "        f'Obj1={obj1:.4f}, Obj2={obj2:.4f}\\n'\n",
    "        f'C23a={params[0]:.2f}, C23b={params[1]:.2f}\\n'\n",
    "        f'C21a={params[2]:.2f}, C21b={params[3]:.2f}',\n",
    "        fontsize=12,\n",
    "        fontweight='bold',\n",
    "        color=color\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pareto_extreme_mid_images.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ========== COMBINED RESULTS PLOT ==========\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# 1. Objective space\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "ax1.scatter(all_Y[:, 0].numpy(), all_Y[:, 1].numpy(), \n",
    "           c='lightblue', s=150, alpha=0.6, edgecolors='gray',\n",
    "           label='All evaluations')\n",
    "ax1.scatter(final_pareto_Y[:, 0].numpy(), final_pareto_Y[:, 1].numpy(), \n",
    "           c='lightcoral', s=200, alpha=0.5, edgecolors='black', \n",
    "           linewidths=1, label='Pareto frontier')\n",
    "\n",
    "# Highlight extreme and mid points\n",
    "colors = []\n",
    "labels_legend = []\n",
    "for idx in selected_indices:\n",
    "    if idx == max_obj1_idx:\n",
    "        colors.append('red')\n",
    "        if 'MAX Obj1' not in labels_legend:\n",
    "            labels_legend.append('MAX Obj1')\n",
    "    elif idx == max_obj2_idx:\n",
    "        colors.append('green')\n",
    "        if 'MAX Obj2' not in labels_legend:\n",
    "            labels_legend.append('MAX Obj2')\n",
    "    elif idx == mid_idx:\n",
    "        colors.append('purple')\n",
    "        if 'Balanced' not in labels_legend:\n",
    "            labels_legend.append('Balanced')\n",
    "    else:\n",
    "        colors.append('orange')\n",
    "\n",
    "for idx, color in zip(selected_indices, colors):\n",
    "    ax1.scatter(final_pareto_Y[idx, 0].numpy(), final_pareto_Y[idx, 1].numpy(),\n",
    "               c=color, s=400, marker='*', edgecolors='black', linewidths=2, zorder=10)\n",
    "\n",
    "ax1.set_xlabel('Objective 1 (Contrast)', fontsize=12)\n",
    "ax1.set_ylabel('Objective 2 (Other Metric)', fontsize=12)\n",
    "ax1.set_title('Pareto Frontier (★ = Extreme/Mid points)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. BO progress\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "iterations = range(len(all_Y))\n",
    "ax2.plot(iterations, all_Y[:, 0].numpy(), 'o-', label='Objective 1', \n",
    "        alpha=0.7, linewidth=2, markersize=8)\n",
    "ax2.plot(iterations, all_Y[:, 1].numpy(), 's-', label='Objective 2', \n",
    "        alpha=0.7, linewidth=2, markersize=8)\n",
    "ax2.axvline(len(train_Y)-1, color='red', linestyle='--', \n",
    "          label='BO start', linewidth=2)\n",
    "ax2.set_xlabel('Iteration', fontsize=12)\n",
    "ax2.set_ylabel('Objective Value', fontsize=12)\n",
    "ax2.set_title('BO Progress', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Hypervolume\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "\n",
    "hv_computer = Hypervolume(ref_point=ref_point)\n",
    "hypervolumes = []\n",
    "for i in range(len(train_Y), len(all_Y) + 1):\n",
    "    current_Y = all_Y[:i]\n",
    "    pareto_mask_i = is_non_dominated(current_Y)\n",
    "    pareto_Y_i = current_Y[pareto_mask_i]\n",
    "    hv = hv_computer.compute(pareto_Y_i)\n",
    "    hypervolumes.append(hv)\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "ax3.plot(range(len(train_Y), len(all_Y) + 1), hypervolumes, 'o-', \n",
    "        linewidth=2, markersize=8, color='purple')\n",
    "ax3.set_xlabel('Iteration', fontsize=12)\n",
    "ax3.set_ylabel('Hypervolume', fontsize=12)\n",
    "ax3.set_title('Hypervolume Improvement', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('multi_objective_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(f\"Total evaluations: {len(all_Y)}\")\n",
    "print(f\"Pareto frontier size: {len(pareto_indices)}\")\n",
    "print(f\"Extreme + Mid points shown: {len(selected_indices)}\")\n",
    "print(f\"Final hypervolume: {hypervolumes[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd5619",
   "metadata": {},
   "source": [
    "### 6. Suggested Exercises:\n",
    "- a) Try different reward functions\n",
    "- b) Try other multiobjective acquisiton functions\n",
    "- c) Try methods other than gaussian processes\n",
    "- d) Try PCA-GP or VAE-GP kind of methods\n",
    "- e) Go for higher order aberrations - and get crazy with choosing parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016331fd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qBO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
